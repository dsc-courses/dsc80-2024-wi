{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948bd3e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0af971",
   "metadata": {},
   "source": [
    "# Lab 5 ‚Äì Missing Values and Imputation\n",
    "\n",
    "## DSC 80, Fall 2023\n",
    "\n",
    "### Due Date: Monday, November 6th at 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96510704",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Welcome to the fifth lab assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note: For Lab 5 only, there are no hidden tests!</b> The tests you see when you run <code>grader.check</code> are the final tests that will determine your grade. In addition, when you submit Lab 5 to Gradescope you will see your final score on the assignment right away. (This is because the lab is due very close to the Midterm Exam.)\n",
    "</div>\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2023-fa).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- **To ensure that all of your work to be submitted is in `lab.py`, we've provided an additional uneditable notebook, called `lab-validation.ipynb`, that contains only the tests and their setup. Make sure you are able to run it top-to-bottom without error before submitting!**\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9de002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dddebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "# DSC 80 preferred styles\n",
    "pio.templates[\"dsc80\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc80\"\n",
    "\n",
    "def create_kde_plotly(df, group_col, group1, group2, vals_col, title=''):\n",
    "    fig = ff.create_distplot(\n",
    "        hist_data=[df.loc[df[group_col] == group1, vals_col], df.loc[df[group_col] == group2, vals_col]],\n",
    "        group_labels=[group1, group2],\n",
    "        show_rug=False, show_hist=False\n",
    "    )\n",
    "    return fig.update_layout(title=title)\n",
    "\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb46135",
   "metadata": {},
   "source": [
    "## Part 1: Missingness Mechanisms\n",
    "\n",
    "First, let's recap the different mechanisms of missingness we studied in lecture.\n",
    "\n",
    "### Missing by Design (MD)\n",
    "- The missing field is deliberately missing. The missing field is deliberately set to null or not collected (hence, \"missing by design\").\n",
    "- The missingness can be exactly predicted when a column will be null, with only knowledge of the other columns using a function of the rows of the dataset.\n",
    "\n",
    "### Missing Completely at Random (MCAR)\n",
    "- The missingness of missing value isn't related to the actual, unreported value itself, nor the values in any other fields. The missingness is not systematic.\n",
    "- The missingness is unconditionally uniform across rows. MCAR doesn't bias the observed data.\n",
    "- There is no relationship between the missing data and the any of the other data, observed or missing.\n",
    "\n",
    "### Missing at Random (MAR)\n",
    "- The missingness of the missing value has nothing to do with the value itself, but may be related to another field.\n",
    "- The missingness is uniform across rows, perhaps conditional on another column. MAR biases the observed data, but is fixable.\n",
    "- There is a systematic relationship between the missing values and the observed data (but not the missing values themselves).\n",
    "- Difference between MD and MAR: If you can *exactly/always* determine missingness using the other columns, the missingness is MD. If there is just some sort of systematic relationship between the missing columns/values and other columns/values that may help us predict missingness, the missingness is MAR.\n",
    "\n",
    "### Not Missing At Random (NMAR)\n",
    "- The missingness of the missing value is related to the actual, unreported value.\n",
    "- NMAR biases the observed data in unobservable ways.\n",
    "- There is relationship between the propensity of a value to be missing and its value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63924d3f",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì After-Purchase Surveys üõí\n",
    "\n",
    "You run a small e-commerce website and send surveys out to customers after they purchase an item from your store. The survey asks whether the customer is satisfied with their purchase (\"Yes\" or \"No\"). Below, you are presented with possible datasets, each of which contains a column `'satisfied'` as described above, as well as a `'customer_id'` number corresponding to the customer and an `'item'` column describing the item that the customer purchased. **The column `'satisfied'` is missing data.**\n",
    "\n",
    "For each of the following datasets, label the column `'satisfied'` as being `'MD'`, `'MCAR'`, `'MAR'`, or `'NMAR'`.\n",
    "\n",
    "1. The dataset consists only of the columns `'customer_id'` and `'satisfied'`.\n",
    "2. The dataset contains the `'customer_id'` of every customer with an account, even if they didn't make a purchase. Also, in this case, you notice everyone who was sent a survey filled it out.\n",
    "3. The dataset contains a column specifying if the user later returned the item.\n",
    "4. The dataset contains a column with the serial number for the item purchased.\n",
    "5. The dataset contains a column with the price of the item purchased.\n",
    "\n",
    "Complete the implementation of the function `after_purchase`, which records your answers and returns a list of length 5, containing the values `'MD'`, `'MCAR'`, `'MAR'`, or `'NMAR'`. For some questions there may be multiple good answers, but there is generally one answer that is \"best\". If you are unsure, ask a tutor, but be prepared to provide justification for whichever answer(s) you think might be right.\n",
    "\n",
    "***Disclaimer***: We know that this lab has no hidden tests, and so it is possible to just look at the correct answers by running `grader.check`. This is not a good idea ‚Äì you should really think about all of the questions here, since similar questions will be on the Midterm Exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1132c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f8863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "out_q1 = after_purchase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f008d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed538927",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì Miscellaneous Missingness Questions üïµÔ∏è\n",
    "\n",
    "In each of the following scenarios, choose the best answer out of the missingness types: `'MD'`, `'MCAR'`, `'MAR'`, and `'NMAR'`. Store your answers in a list of length 5, and complete the implementation of the function `multiple_choice`, which returns that list.\n",
    "\n",
    "1. UCSD has recently adopted GrubHub as the food pre-ordering app for campus restaurants, so you can order your food ahead of time and stop by before your next class. In a DataFrame of GrubHub app orders, which contains information such as `'restaurant'`, `'name'`, `'items'`, and `'total'`, the column `'delivery_address'` is often missing for UCSD students. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "2. In a database of student records that records student profile data, such as `'name'`, `'home_address'`, `'ethnicity'`, etc., sometimes the `'middle_name'` column is missing. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "3. The UCSD Club Basketball team creates a signup sheet for potential new members. The sheet contains the columns `'full_name'`, `'year'`, `'email'`, `'favorite_sports'`, `'number_of_sports_played'`, and `'sports_previously_played'`. The team president notices that many students left the `'sports_previously_played'` column blank. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "4. After the 2023 Sun God Festival, Associated Students sends out a survey to all students about whether their expectations for the 2022 Sun God Festival were met, with all questions being optional. They notice that many students left the \"Were you satisfied with the 2023 Sun God Festival?\" question blank. Which is the most likely missingness mechanism for answers to this question?\n",
    "\n",
    "\n",
    "5. UCSD has been using a two-factor authentication system, DUO, since October 16th, 2019. When using DUO, all UCSD accounts are assigned a unique code. UCSD's Service Desk, who maintains DUO, has a database that stores each user's code and their phone number, which users must provide when they sign up for DUO. They notice that many phone numbers are missing. Which is the most likely missingness mechanism for phone numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a435368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "out_q2 = multiple_choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db0089",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d570d",
   "metadata": {},
   "source": [
    "## Part 2: Assessing Missingness Through Data\n",
    "\n",
    "Great, we're familiar with the various ways in which data can be missing. Let's now focus on deciding whether data in a particular column look MCAR or MAR through permutation tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6e1ee",
   "metadata": {},
   "source": [
    "### Question 3 ‚Äì Payment Data üí∞\n",
    "\n",
    "In `data/payment.csv`, you are given a dataset of payment information for purchases made on January 1st, 2019. The dataset contains the customers' `'id'`, `'credit_card_type'`, `'credit_card_number'`, and `'date_of_birth'`.\n",
    "\n",
    "You'd like to assess whether the missingness of `'credit_card_number'` is dependent on the age of the customer. Here's how you'll proceed:\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `first_round`\n",
    "\n",
    "Look at distribution of ages by missingness of `'credit_card_number'` and determine if the missingness is dependent on age or not.\n",
    "\n",
    "Use the following steps to approach this problem:\n",
    "\n",
    "- Compute the ages of the customers. To find a customer's age, compute the number of years between their birth year and 2024.\n",
    "- Draw the distribution of ages by missingness of `'credit_card_number'`. Specifically, you will draw two histograms or density curves:\n",
    "    - One of ages where `'credit_card_number'` is missing.\n",
    "    - One of ages where `'credit_card_number'` is not missing.\n",
    "    You can use the `create_kde_plotly` helper function imported at the top of the notebook to help you, if you'd like.\n",
    "- Perform a permutation test for whether or not the two distributions mentioned above are drawn from the same population distribution. Use a 5% significance level. Use the **absolute difference of means** as your test statistic.\n",
    "\n",
    "Note that some of the ages themselves are also missing; you don't need to do anything about this.\n",
    "\n",
    "Complete the implementation of the function `first_round`, which takes in no arguments that returns a **list** with two values:\n",
    "* The first value is the p-value from your permutation test. \n",
    "* The second value is either `'R'` if you reject the null hypothesis, or `'NR'` if you fail to reject the null.\n",
    "\n",
    "**Does the result match your guess? If not, what might be a problem?**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `second_round`\n",
    "\n",
    "Repeat the same permutation test as in `first_round`, but this time, use the **Kolmogorov-Smirnov statistic** as your test statistic.\n",
    "\n",
    "Complete the implementation of the function `second_round` with no arguments that returns a __list__ with three values: \n",
    "* The first value is the p-value from your new permutation test.\n",
    "* The second value is either `'R'` if you reject the null hypothesis, or `'NR'` if you fail to reject the null. \n",
    "* The third value is your final conclusion: `'D'` (the missingness of `'credit_card_number'` is dependent on age) or `'ND'` (the missingness of `'credit_card_number'` is not dependent on age).\n",
    "\n",
    "Note that in [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html), we ran permutation tests using the Kolmogorov-Smirnov test statistic **without `for`-loops**. You can use this same procedure; we have already imported `stats` from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your permutation tests in the Jupyter Notebook\n",
    "# and put your final results in lab.py.\n",
    "payments_fp = Path('data') / 'payment.csv'\n",
    "payments = pd.read_csv(payments_fp)\n",
    "payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f29f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af069238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "first_pval, first_result = first_round()\n",
    "second_pval, second_result, second_result1 = second_round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e4d0e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce912b9",
   "metadata": {},
   "source": [
    "### Question 4 ‚Äì Missing Heights üïµÔ∏è\n",
    "\n",
    "In the file `data/missing_heights.csv` are the heights of adult children and their fathers (`'child'` and `'father'`). The `'child_X'` columns are missing values in varying proportions; for each X, `'child_X'` is X\\% not missing (and hence (100-X)\\% missing). **The missingness of these `'child_X'` columns were created as MAR dependent on father's heights (similar to what was done in [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html)). The missingness of these `'child_X'` columns are all equally dependent on father's heights.**\n",
    "\n",
    "You will attempt to **verify** the missingness of the `'child_X'` columns as being dependent on the `'father'` column by using permutation tests. Your permutation tests should use the Kolmogorov-Smirnov test statistic. You can use `scipy.stats`' built-in K-S function to run your permutation tests and compute your p-values; you don't need to simulate manually using a `for`-loop.\n",
    "\n",
    "To do this, complete the implementation of the function `verify_child`, which takes in the `heights` DataFrame and returns a Series of p-values from your permutation tests, indexed by the names of the columns in `heights` that are formatted like `'child_X'` (that is, its index should be `'child_95'`, `'child_90'`, ..., `'child_5'`; the order of the Series is not important).\n",
    "\n",
    "Unlike in Question 3, your permutation tests should run within your `verify_child` function. You can loop over the **columns** of `heights`, but you shouldn't need to use a `for`-loop to actually conduct your permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f2b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfee58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "heights = pd.read_csv(heights_fp)\n",
    "out_q4 = verify_child(heights.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e801836",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6646bc4d",
   "metadata": {},
   "source": [
    "Let's reflect on the $p$-values you discovered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff264c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    out_q4\n",
    "    .to_frame()\n",
    "    .plot(kind='barh', width=800, height=400, labels={'index': 'column', 'value': 'p-value'})\n",
    "    .update_layout(showlegend=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d2ab1",
   "metadata": {},
   "source": [
    "Remember, **in all seven columns, the data are truly MAR** ‚Äì we know this for a fact since we were told in the question:\n",
    "\n",
    "> The missingness of these <code>'child_X'</code> columns were created as MAR dependent on father's heights (similar to what was done in [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html)). The missingness of these <code>'child_X'</code> columns are all equally dependent on father's heights.\n",
    "\n",
    "- If our permutation test returned a small $p$-value for a particular column, it means that the distribution of father's heights in rows where the child's height was missing looked significantly different than the distribution of father's heights in rows where the child's height was present. That's evidence that the missingness of that column depends on father's heights.\n",
    "\n",
    "- If our permutation test returned a large $p$-value for a particular column, that's evidence that the missingness of that column doesn't depend on father's heights.\n",
    "\n",
    "Despite the fact that the missingness of each `'child_X'` column truly depends on father's heights (by design), it appears that **in all cases except `'child_50'`, we'd conclude that the child's height columns are MCAR** at the 5% significance level! We should be precise ‚Äì we cannot **prove** that heights are MCAR or MAR, just like we cannot prove either hypothesis in a hypothesis test. Instead, all we can say, for instance, is that two samples don't look like they were drawn from the same population distribution, and hence, the missingness of a particular column **appears** to be dependent on another column.\n",
    "\n",
    "One thing you'll notice is that when a column contains relatively few missing values, it is exceedingly difficult to conclude that values in that column are missing at random dependent on another column. Think about why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87306ddc",
   "metadata": {},
   "source": [
    "## Part 3: Imputation\n",
    "\n",
    "Now that we're comfortable with missingness mechanisms and how to detect them through data, let's focus on filling in missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20afbcd2",
   "metadata": {},
   "source": [
    "### Question 5 ‚Äì Imputing Heights üßçüìè\n",
    "\n",
    "In [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html), you learned how to perform single-valued imputation conditionally on a **categorical** column: impute with the mean for each group. That is, for each distinct value of the **categorical** column, there is a single imputed value.\n",
    "\n",
    "Here, you will perform single-valued imputation by conditioning on a **quantitative** column. \n",
    "\n",
    "You will work with a version of the `heights` DataFrame, `new_heights`, that has a `'father'` column and a single `'child'` column. The `'child'` column has missing values. To impute the `'child'` column, transform the `'father'` column into a categorical column by binning the values of `'father'` into [quartiles](https://en.wikipedia.org/wiki/Quartile). Once this is done, you can impute `'child'` as in lecture (and described above).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `cond_single_imputation`\n",
    "\n",
    "Complete the implementation of the function `cond_single_imputation`, which takes in a DataFrame with columns `'father'` and `'child'` (where `'child'` has missing values) and performs a single-valued mean imputation of the `'child'` column, conditional on `'father'`. Your function should return a **Series**.\n",
    "\n",
    "***Hints***:\n",
    "- `pd.qcut` may be helpful (as you likely learned in Project 2)!\n",
    "- The `transform` method is useful for this question (see [Lecture 3](https://dsc80.com/resources/lectures/lec03/lec03.html#Transformations)), though it's also possible to do this using the `aggregate` method.\n",
    "- As a reminder, *loops are not allowed*, and functions mentioned in \"Hints\" are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd68bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d3c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "new_heights = pd.read_csv(heights_fp)[['father', 'child_50']]\n",
    "new_heights = new_heights.rename(columns={'child_50': 'child'})\n",
    "out_q5 = cond_single_imputation(new_heights.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "heights_q5 = pd.read_csv(heights_fp)\n",
    "heights_q5['child'] = heights_q5['child_50']\n",
    "inp_q5 = heights_q5\n",
    "out_q5 = cond_single_imputation(inp_q5)\n",
    "df_q5 = inp_q5.copy()\n",
    "df_q5['imputed'] = out_q5\n",
    "gp1_q5 = df_q5.groupby('father')['imputed'].mean()\n",
    "gp2_q5 = df_q5.groupby('father')['child'].mean()\n",
    "m_q5 = (pd.concat([gp1_q5, gp2_q5], axis=1)\n",
    "     .dropna().diff(axis=1).abs().iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344c1e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57333e5d",
   "metadata": {},
   "source": [
    "### Question 6 ‚Äì Probabilistic Imputation üé≤\n",
    "\n",
    "In [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html), you learned how to impute a quantitative column by sampling from the observed values. **One problem with this technique is that the imputation will never generate imputed values that weren't already in the dataset.** For example, 57, 57.5, and 59 are values in the `'child'` column of `new_heights` while 58 is not. Thus, any imputation done by sampling from the observed values in the `'child'` column will not be able to generate a height of 58, even though it's clearly a reasonable value to occur in the dataset.\n",
    "\n",
    "To keep things simple, you will impute the `'child'` column **unconditionally** from the distribution of `'child'` heights present in the dataset. This means that you will use the values present in `'child'` to impute missing values, without looking at other columns.\n",
    "\n",
    "An approach to quantitative imputation that overcomes the limitation mentioned above is as follows:\n",
    "- Create a histogram of observed `'child'` heights, using 10 bins.\n",
    "- Use the histogram to generate a number within the observed range of `'child'` heights:\n",
    "    - The likelihood a generated number belongs to a given bin is equal to the area of that bin. (Remember, in histograms, areas are proportions.)\n",
    "    - Any number within a fixed bin is equally likely to occur.\n",
    "    \n",
    "Let's illustrate this approach with an example. Let `demo` be the array of 10 numbers defined below.\n",
    "\n",
    "```py\n",
    "demo = np.array([10, 11, 11, 13, 14, 14, 13.5, 14, 15, 16])\n",
    "```\n",
    "\n",
    "- The first step is creating a histogram of `demo`. Note that with this small dataset, we will use 3 bins, but you will be using 10 bins in your imputation process.\n",
    "\n",
    "<img src='imgs/demo_histogram.png' width=300>\n",
    "\n",
    "- Note that in your process, you don't actually need to draw a histogram ‚Äì instead, use `np.histogram`.\n",
    "- In the histogram above, we see that $2 \\cdot 0.15 = 0.3 = 30\\%$ of values lie in the [10, 12) bin, $2 \\cdot 0.1 = 0.2 = 20\\%$ of values lie in the [12, 14) bin, and $2 \\cdot 0.25 = 0.5 = 50\\%$ of values lie in the [14, 16] bin.\n",
    "- Next, we need to pick a bin at random. There's a 30\\% chance we pick the [10, 12) bin, a 20\\% chance we pick the [12, 14) bin, and a 50\\% chance we pick the [14, 16] bin. `np.random.choice` will be helpful in picking a bin at random.\n",
    "- Once we pick a bin, we pick a number **uniformly at random** from within the bin. For instance, suppose we randomly chose the [14, 16] bin in the previous step. We then must select a (real) number between 14 and 16 uniformly at random. `np.random.uniform` can help you here.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `quantitative_distribution`\n",
    "    \n",
    "Complete the implementation of the function `quantitative_distribution`, which takes in a Series, `child`, in which some values are missing, and a positive integer `N`, and returns an **array** of `N` imputed values using the method described above. \n",
    "\n",
    "***Note***: You may use a `for`-loop.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `impute_height_quant`\n",
    "\n",
    "Complete the implementation of the function `impute_height_quant`, which takes in a Series, `child`, in which some values are missing and imputes them using the scheme above. `impute_height_quant` should return a Series that is the same length of `child` but with no missing values. **You should use `quantitative_distribution` to help you do this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb03b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd0a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748106c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "heights_fp = Path('data') / 'missing_heights.csv'\n",
    "heights = pd.read_csv(heights_fp)\n",
    "child = heights['child_50']\n",
    "quantitative_distribution_out_q6 = quantitative_distribution(child.copy(), 100)\n",
    "impute_height_quant_out_q6 = impute_height_quant(child.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23f86e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234df3d",
   "metadata": {},
   "source": [
    "### Question 7 ‚Äì The Rules of Web Scraping üöî\n",
    "\n",
    "In Lecture 9, we will start studying web scraping. This question will give you an introduction to the rules behind it.\n",
    "\n",
    "Many sites have a published policy allowing or disallowing automatic access to their site. Often, this policy is in a text file named `robots.txt`. [Here is a good article](https://moz.com/learn/seo/robotstxt) that explains what these files are, where to find them, and how to use them. **After reading the article**, please answer the following questions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Multiple-Choice Questions\n",
    "\n",
    "**1. What is the purpose of `robots.txt`?**\n",
    "\n",
    "1. To informs agents which pages to crawl.\n",
    "\n",
    "2. To informs agents that the site is automated.\n",
    "\n",
    "3. To inform agents that robots will chase them down if their info is stolen.\n",
    "\n",
    "\n",
    "**2. Where do you put your `robots.txt` file?**\n",
    "\n",
    "1. In the folder you want to disallow.\n",
    "\n",
    "2. In the root directory of your website.\n",
    "\n",
    "3. In a Google search.\n",
    "\n",
    "**3. Is it illegal to scrape a site if there is no `robots.txt` present?** (***Hint***: [Read this](https://medium.com/@tjwaterman99/web-scraping-is-now-legal-6bf0e5730a78) if you're not sure. If you aren't able to access the article because Medium says \"You've read all your free member-only stories...\", try opening the article in a new incognito or private browsing window üòÖ.)\n",
    "\n",
    "1. Yes.\n",
    "\n",
    "2. No.\n",
    "\n",
    "**4. Can each subdomain on a root domain use separate `robots.txt` files?**\n",
    "\n",
    "1. Yes.\n",
    "\n",
    "2. No.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Website Hunt\n",
    "\n",
    "1. Find at least one website that explicitly uses a `robots.txt` file and allows scraping by everyone. One such site is [singleplatform.com](https://places.singleplatform.com) (see [https://places.singleplatform.com/robots.txt](https://places.singleplatform.com/robots.txt)); find another one.\n",
    "\n",
    "2. Find at least one website that explicitly uses a `robots.txt` file and does not allow scraping by generic user-agents. One such site is [linkedin.com](https://www.linkedin.com) (see [linkedin.com/robots.txt](https://www.linkedin.com/robots.txt)); find another one.\n",
    "\n",
    "\n",
    "When browsing through `robots.txt` files, you may notice that some have entries for several different user-agents. The user-agent you are interested in for this question is the generic user-agent, which is denoted by `*`. A `/` after a `Disallow:` indicates that no scraping is allowed, whereas nothing after the `Disallow:` or a `/` after `Allow:` indicates that all scraping is allowed.\n",
    "\n",
    "***Notes***:\n",
    "- During your search, you may notice that very few websites allow scraping by everyone. When trying to find websites that satisfy this criteria, you are encouraged to think contextually about what kinds of websites would and wouldn't mind you scraping their data. Would a government website likely mind scraping by everyone? How about a website someone created just for fun?\n",
    "\n",
    "- Some websites may cause Gradescope to time out. Please change a website if you encounter this issue. \n",
    "\n",
    "- Below, you are asked to store the URLs of the websites you find in a list. When storing URLs, you can add `'/robots.txt'` to the end, but you don't have to ‚Äì either format will be accepted.\n",
    "- **You cannot use singleplatform.com or linkedin.com as your examples!**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### `answers`\n",
    "\n",
    "Complete the implementation of the function `answers`, which takes in no arguments and returns **two lists**:\n",
    "\n",
    "* one containing your answers to the multiple-choice questions, and\n",
    "* one containing the URLs of the two sites you found, in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67509f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8853f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "mc_answers, websites = answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa480226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "from urllib.parse import urlparse\n",
    "import urllib.robotparser\n",
    "\n",
    "# This code checks the robots.txt file\n",
    "def canFetch(url):\n",
    "    if url[:4] != 'http':\n",
    "        url = 'https://' + url\n",
    "    parsed_uri = urlparse(url)\n",
    "\n",
    "    domain = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "    rp.set_url(domain + \"/robots.txt\")\n",
    "    try:\n",
    "        rp.read()\n",
    "        canFetchBool = rp.can_fetch(\"*\", url)\n",
    "    except:\n",
    "        canFetchBool = None\n",
    "    \n",
    "    return canFetchBool\n",
    "\n",
    "ans_q7, websites_q7 = answers()\n",
    "canfetch_q7 = []\n",
    "for site in websites_q7:\n",
    "    try:\n",
    "        canfetch_q7.append(canFetch(site))\n",
    "    except:\n",
    "        canfetch_q7.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef8ae1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc46f1",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 5! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` ‚Äì that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q2 q4\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 2, and 4 ‚Äì again, only using the code in `lab.py`. [This video](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=5acc92e6-0dfe-4555-9b6a-8115b6a52f99) how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d613a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f049eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f5403",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(out_q1) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(out_q1) <= set(['MD', 'MCAR', 'MAR', 'NMAR'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[0] == 'NMAR'\nTrue",
         "failure_message": "sub-question 1: reviewers are more likely to review when dissatified",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[0] in ['NMAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 1: partial; one column must be NMAR or MCAR",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[1] == 'MD'\nTrue",
         "failure_message": "sub-question 2: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[1] in ['MD', 'MAR']\nTrue",
         "failure_message": "sub-question 2: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out_q1[2] == 'MAR'\nTrue",
         "failure_message": "sub-question 3: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[2] in ['NMAR', 'MAR']\nTrue",
         "failure_message": "sub-question 3: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out_q1[3] in ['NMAR', 'MAR']\nTrue",
         "failure_message": "sub-question 4: not the optimal answer, how does having a serial number affect missingness?",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[3] in ['NMAR', 'MAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 4: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out_q1[4] == 'MAR'\nTrue",
         "failure_message": "sub-question 5: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q1[4] in ['MAR', 'NMAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 5: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(out_q2) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(out_q2) <= set(['MD', 'MCAR', 'MAR', 'NMAR'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[0] == 'MAR'\nTrue",
         "failure_message": "sub-question 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[0] in ['MCAR', 'MAR', 'NMAR']\nTrue",
         "failure_message": "sub-question 1: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[1] in ['MAR', 'NMAR']\nTrue",
         "failure_message": "sub-question 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[2] in ['MD', 'MAR']\nTrue",
         "failure_message": "sub-question 3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[3] == 'NMAR'\nTrue",
         "failure_message": "sub-question 4",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[3] in ['NMAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 4: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[4] == 'MCAR'\nTrue",
         "failure_message": "sub-question 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q2[4] in ['MAR', 'NMAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 5: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(first_round(), list) and isinstance(second_round(), list)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> len(first_round()) == 2 and len(second_round()) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> first_pval < 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> first_result in ['NR', 'R']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> second_pval < 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> second_result in ['NR', 'R']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> second_result1 in ['ND', 'D']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(first_pval, 0.16, atol=0.4)\nTrue",
         "failure_message": "first_round p-value approximate",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> first_result == 'NR'\nTrue",
         "failure_message": "first_round result -- reject / do not reject",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> second_result1 == 'D'\nTrue",
         "failure_message": "part 3 multiple choice",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(second_pval, 0.02, atol=0.2)\nTrue",
         "failure_message": "second_round p-value approximate",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(second_pval, 0.02, atol=0.1)\nTrue",
         "failure_message": "second_round p-value approximate",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(second_pval, 0.02, atol=0.02)\nTrue",
         "failure_message": "second_round p-value",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> second_result == 'R'\nTrue",
         "failure_message": "second_round result -- reject / do not reject",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_q4['child_50'] < out_q4['child_95']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out_q4['child_5'] > out_q4['child_50']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out_q4['child_95'] > out_q4['child_5']\nTrue",
         "failure_message": "95 > 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_q4['child_75'] > out_q4['child_25']\nTrue",
         "failure_message": "75 > 25",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_q4['child_50'], 0, atol=0.02)\nTrue",
         "failure_message": "pvalue of child_50",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_q4['child_25'], 0.06, atol=0.2)\nTrue",
         "failure_message": "pvalue of child_25",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_q4['child_95'], 0.8, atol=0.2)\nTrue",
         "failure_message": "pvalue of child_95",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_q5.isna().sum() == 0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (new_heights['child'].std() - out_q5.std()) > 0.5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_q5.mean(), inp_q5['child'].mean(),atol=0.2)\nTrue",
         "failure_message": "means are close",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(m_q5, 0, atol=2))\nTrue",
         "failure_message": "group-wise means are close: very approx",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(m_q5.median(), 0.314, atol=0.1)\nTrue",
         "failure_message": "group-wise means are close: approx",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(m_q5.median(), 0.31439, atol=0.01)\nTrue",
         "failure_message": "group-wise means are close",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> quantitative_distribution_out_q6.min() >= 56\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> quantitative_distribution_out_q6.max() <= 79\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(quantitative_distribution_out_q6.mean(), child.mean(), atol=1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(quantitative_distribution_out_q6.std(), 3.5, atol=0.65)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> impute_height_quant_out_q6.isna().sum() == 0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(impute_height_quant_out_q6.mean(), child.mean(), atol=0.5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (set(quantitative_distribution_out_q6) - set(child.dropna())) != {}\nTrue",
         "failure_message": "new values",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (set(impute_height_quant_out_q6) - set(child.dropna())) != {}\nTrue",
         "failure_message": "new values",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(mc_answers) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(websites) >= 2\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ans_q7[0] == 1\nTrue",
         "failure_message": "multiple choice: 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ans_q7[1] == 2\nTrue",
         "failure_message": "multiple choice: 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ans_q7[2] == 2\nTrue",
         "failure_message": "multiple choice: 3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ans_q7[3] == 1\nTrue",
         "failure_message": "multiple choice: 4",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('singleplatform.com' not in ''.join(websites)) and ('linkedin.com' not in ''.join(websites))\nTrue",
         "failure_message": "no singleplatform or linkedin!",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> True in canfetch_q7\nTrue",
         "failure_message": "at least one that can scrape",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> False in canfetch_q7\nTrue",
         "failure_message": "at least one that can not scrape",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
