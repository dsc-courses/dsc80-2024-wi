{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *\n",
    "import lec15_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15 ‚Äì Standardization, Multicollinearity, and Generalization\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc9d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/chatgpt.png\" width=60%><i>Earlier today.</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Project 3 is due **tonight**.\n",
    "- Lab 8 is due on **Monday, March 4th**.\n",
    "- Project 4 is released! Read all about it at [**dsc80.com/proj04**](https://dsc80.com/proj04).\n",
    "    - The checkpoint is due on **Thursday, March 7th**.\n",
    "    - The full project is due on **Thursday, March 21st**. You **cannot** use slip days on the final deadline.\n",
    "- The Final Exam is on **Tuesday, March 19th from 3-6PM**.\n",
    "    - Practice by working through old exams at [practice.dsc80.com](https://practice.dsc80.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013fb29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RSVP to the senior capstone showcase on March 15th!\n",
    "\n",
    "The senior capstone showcase is on Friday, March 15th in the **Price Center East Ballroom**. The DSC seniors will be presenting posters on their capstone projects. Come and ask them questions; if you're a DSC major, this will be you one day!\n",
    "\n",
    "<center><img src=\"imgs/Quarter 2 Project Poster.jpeg\" width=600><i>Last year's showcase.</i></center>\n",
    "\n",
    "The session is broken into two blocks:\n",
    "\n",
    "- Block 1: 11AM-12:30PM.\n",
    "- Block 2: 1-2:30PM.\n",
    "\n",
    "<center>\n",
    "<h3>Look at the list of topics and RSVP at <a href=\"https://hdsishowcase.com\">hdsishowcase.com</a>!\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Standardization.\n",
    "- Multicollinearity.\n",
    "- Generalization.\n",
    "    - Bias and variance.\n",
    "    - Train-test splits.\n",
    "    \n",
    "Today's lecture will be _mostly_ theoretical!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398eb093",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c7567",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5587821",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review: Transformers, models, and `Pipeline`s\n",
    "\n",
    "Last class, we learned how to build a `Pipeline` in `sklearn`. A `Pipeline` consists of:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381bab6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- transformers (from `sklearn.preprocessing`), which **engineer features**, and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afdebb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a model (from `sklearn.linear_model`), which is trained to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a28d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's import the necessary classes and functions from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error # New!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f9951",
   "metadata": {},
   "source": [
    "Let's also re-import our trusty `tips` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777015f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example `Pipeline`\n",
    "\n",
    "One of the transformers we used was the `StandardScaler` transformer, which **standardizes** columns.\n",
    "\n",
    "$$z(x_i) = \\frac{x_i - \\text{mean of } x}{\\text{SD of } x}$$\n",
    "\n",
    "Let's build a `Pipeline` that:\n",
    "- Takes in the `'total_bill'` and `'size'` features of `tips`.\n",
    "- Standardizes those features.\n",
    "- Uses the resulting standardized features to fit a linear model that predicts `'tip'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7799cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define these once, since we'll use them repeatedly.\n",
    "X = tips[['total_bill', 'size']]\n",
    "y = tips['tip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_std = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "model_with_std.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20184d8a",
   "metadata": {},
   "source": [
    "How well does our model do? We can compute its $R^2$ and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75de59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_with_std.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, model_with_std.predict(X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395de73c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Does this model perform any better than one that _doesn't_ standardize its features? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_std = LinearRegression()\n",
    "model_without_std.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_std.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cfbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, model_without_std.predict(X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37078e9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**No!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac9790",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The purpose of standardizing features\n",
    "\n",
    "If you're performing \"vanilla\" linear regression ‚Äì that is, using the `LinearRegression` object ‚Äì then standardizing your features **will not** change your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdf45d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are other models where standardizing your features _will_ improve performance, because the methods assume features are standardized.\n",
    "    - Regularized linear regression (see [DSC 140A](https://dsc140a.com)).\n",
    "    - PCA (assumes centered data, not necessarily standardized: see [DSC 140B](https://dsc140b.com)).\n",
    "    - Clustering algorithms, e.g. $k$-means clustering (saw in DSC 40A!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede8a13",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There _is_ a benefit to standardizing features when performing vanilla linear regression, as we saw in DSC 40A: the features are brought to the same scale, so the coefficients can be compared directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total bill, table size.\n",
    "model_without_std.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec928373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total bill, table size.\n",
    "model_with_std.named_steps['lin-reg'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b4fd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847fde4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heights and weights\n",
    "\n",
    "We have a dataset containing the weights and heights of 25,000 18 year olds, taken from [here](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e382366",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_path = Path('data') / 'SOCR-HeightWeight.csv'\n",
    "people = pd.read_csv(people_path).drop(columns=['Index'])\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "people.plot(kind='scatter', x='Height (Inches)', y='Weight (Pounds)', \n",
    "            title='Weight vs. Height for 25,000 18 Year Olds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483891c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivating example\n",
    "\n",
    "Suppose we fit a simple linear regression model that uses **height in inches** to predict **weight in pounds**.\n",
    "\n",
    "$$\\text{predicted weight (pounds)} = w_0 + w_1 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = people[['Height (Inches)']]\n",
    "y = people['Weight (Pounds)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea69ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_feat = LinearRegression()\n",
    "lr_one_feat.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc718153",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$w_0^*$ and $w_1^*$ are shown below, along with the model's training set RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f24dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_feat.intercept_, lr_one_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ede43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, lr_one_feat.predict(X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6717fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, suppose we fit another regression model, that uses **height in inches** AND **height in centimeters** to predict weight.\n",
    "\n",
    "$$\\text{predicted weight (pounds)} = w_0 + w_1 \\cdot \\text{height (inches)} + w_2 \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "people['Height (cm)'] = people['Height (Inches)'] * 2.54 # 1 inch = 2.54 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26777067",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = people[['Height (Inches)', 'Height (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_two_feat = LinearRegression()\n",
    "lr_two_feat.fit(X2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52ada7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What are $w_0^*$, $w_1^*$, $w_2^*$, and the model's test RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_two_feat.intercept_, lr_two_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d37245",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, lr_two_feat.predict(X2), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e9ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Observation**: The intercept is the same as before (roughly -82.57), as is the RMSE. However, the coefficients on `'Height (Inches)'` and `'Height (cm)'` are massive in size!\n",
    "\n",
    "What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe1e42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redundant features\n",
    "\n",
    "Let's use simpler numbers for illustration. Suppose in the first model, $w_0^* = -80$ and $w_1^* = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee9e2f",
   "metadata": {},
   "source": [
    "$$\\text{predicted weight (pounds)} = -80 + 3 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57392da8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the second model, we have:\n",
    "\n",
    "$$\\begin{align*}\\text{predicted weight (pounds)} &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\text{height (cm)} \\\\ &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\big( 2.54^* \\cdot \\text{height (inches)} \\big) \\\\ &= w_0^* + \\left(w_1^* + 2.54 \\cdot w_2^* \\right) \\cdot \\text{height (inches)} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ddd66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the first model, we already found the \"best\" intercept ($-80$) and slope ($3$) in a linear model that uses height in inches to predict weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28149c8f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**So, as long as $w_1^* + 2.54 \\cdot w_2^* = 3$ in the second model, the second model's training predictions will be the same as the first, and hence they will also minimize RMSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489bc9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Infinitely many parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e03a59",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Issue**: There are an infinite number of $w_1^*$ and $w_2^*$ that satisfy $w_1^* + 2.54 \\cdot w_2^* = 3$!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ea315",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 - 10 \\cdot \\text{height (inches)} + \\frac{13}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708169d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 + 10 \\cdot \\text{height (inches)} - \\frac{7}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd398c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both prediction rules look very different, but actually make the same predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b5e83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `lr.coef_` could return either set of coefficients, or any other of the infinitely many options. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d3015",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But neither set of coefficients is **has any meaning!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247562aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(-80 - 10 * people.iloc[:, 0] + (13 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "(-80 + 10 * people.iloc[:, 0] - (7 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb367e38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6782dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity occurs when features in a regression model are **highly correlated** with one another.\n",
    "    - In other words, multicollinearity occurs when **a feature can be predicted using a linear combination of other features, fairly accurately**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b361d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When multicollinearity is present in the features, the **coefficients in the model** are uninterpretable ‚Äì they have no meaning.\n",
    "    - A \"slope\" represents \"the rate of change of $y$ with respect to a feature\", when all other features are held constant ‚Äì but if there's multicollinearity, you can't hold other features constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd925703",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Note: Multicollinearity doesn't impact a model's predictions!**\n",
    "    - It doesn't impact a model's ability to generalize to unseen data.\n",
    "    - If features are multicollinear in the training data, they will probably be multicollinear in the test data too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f36b83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solutions**:\n",
    "    - Manually remove highly correlated features.\n",
    "    - Use a dimensionality reduction technique (such as PCA) to automatically reduce dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacea60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding\n",
    "\n",
    "**A one hot encoding will result in multicollinearity unless you drop one of the one hot encoded features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da2ba8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose we have the following fitted model:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(x) = 1 + 2 \\cdot (\\text{smoker==Yes}) - 2 \\cdot (\\text{smoker==No})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa205b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is equivalent to:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(x) = 10 - 7 \\cdot (\\text{smoker==Yes}) - 11 \\cdot (\\text{smoker==No})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a1914",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Solution: Drop one of the one hot encoded columns. `sklearn.preprocessing.OneHotEncoder` has an option to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29e43e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `Pipeline`s of just transformers\n",
    "\n",
    "If you want to apply multiple transformations to the same column in a dataset, you can create a `Pipeline` just for that column.\n",
    "\n",
    "For example, suppose we want to:\n",
    "- One hot encode the `'sex'`, `'smoker'`, and `'time'` columns, dropping one column per feature.\n",
    "- One hot encode the `'day'` column, but as either `'Weekday'`, `'Sat'`, or `'Sun'`, again, dropping one column per feature.\n",
    "- Binarize the `'size'` column.\n",
    "\n",
    "Here's how we might do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5506e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekend(s):\n",
    "    # The input to is_weekend is a Series!\n",
    "    return s.replace({'Thur': 'Weekday', 'Fri': 'Weekday'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea58b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4726324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_day = Pipeline([\n",
    "    ('is-weekend', FunctionTransformer(is_weekend)),\n",
    "    ('ohe', OneHotEncoder(drop='first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38727cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_trans = ColumnTransformer([\n",
    "    ('transform-day', pl_day, ['day']),\n",
    "    ('ohe-others', OneHotEncoder(drop='first'), ['sex', 'smoker', 'time']),\n",
    "    ('binarize-size', Binarizer(threshold=2), ['size'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e92005",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('transf', col_trans),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])\n",
    "\n",
    "pl.fit(tips.drop('tip', axis=1), tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51363a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many coefficients does the resulting linear model have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c680747",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['lin-reg'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8f4b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06fdef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity is present in a linear model when one feature can be accurately predicted using one or more other features.\n",
    "    - In other words, it is present when a feature is **redundant**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd480761",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multicollinearity doesn't pose an issue for prediction; it doesn't hinder a model's ability to generalize. Instead, it renders the **coefficients** of a linear model meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a133b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c0fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "    \n",
    "_Taken from [Problem 9 on the Fall 2023 Final Exam](https://practice.dsc80.com/fa23-final#problem-9)._\n",
    "\n",
    "<center><img src=\"imgs/fish-exam-prob.png\" width=100%></center>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29f107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515aed4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906265c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You and Billy are studying for an upcoming exam. You both decide to test your understanding by taking a **practice exam**.\n",
    "    - Your logic: If you do well on the practice exam, you should do well on the real exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d060d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You each take the practice exam once and look at the solutions afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f457b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Your strategy**: Memorize the answers to all practice exam questions, e.g. \"Question 1: A; Question 2: C; Question 3: A.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ad577",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Billy's strategy**: Learn high-level concepts from the solutions, e.g. \"data are NMAR if the likelihood of missingness depends on the missing values themselves.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26344c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Who will do better on the **practice exam**? Who will probably do better on the **real exam**? üßê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a59976",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the quality of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2051d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, we've computed the RMSE (and $R^2$) of our fit regression models on the **data that we used to fit them**, i.e. the **training data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a762c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've said that Model A is **better** than Model B if Model A's RMSE is **lower** than Model B's RMSE.\n",
    "    - Remember, our **training data** is a sample from some population.\n",
    "    - Just because a model fits the training data well doesn't mean it will **generalize** and work well on **similar, unseen samples** from the same population!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c467ec3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Overfitting and underfitting\n",
    "\n",
    "Let's collect two samples $\\{(x_i, y_i)\\}$ from the same population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23) # For reproducibility.\n",
    "\n",
    "def sample_from_pop(n=100):\n",
    "    x = np.linspace(-2, 3, n)\n",
    "    y = x ** 3 + (np.random.normal(0, 3, size=n))\n",
    "    return pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "sample_1 = sample_from_pop()\n",
    "sample_2 = sample_from_pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f617db",
   "metadata": {},
   "source": [
    "For now, let's just look at Sample 1. The relationship between $x$ and $y$ is roughly **cubic**; that is, $y \\approx x^3$ (remember, in reality, you won't get to see the population)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca2247",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9c50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial regression\n",
    "\n",
    "Let's fit three **polynomial** models on Sample 1:\n",
    "- Degree 1.\n",
    "- Degree 3.\n",
    "- Degree 25.\n",
    "\n",
    "The `PolynomialFeatures` transformer will be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform fits and transforms the same input.\n",
    "d2 = PolynomialFeatures(3)\n",
    "d2.fit_transform(np.array([1, 2, 3, 4, -2]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e37f18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below, we look at our three models' predictions on Sample 1 (which they were trained on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the definition of train_and_plot in lec15_util.py if you're curious as to how the plotting works.\n",
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_1, degs=[1, 3, 25], data_name='Sample 1')\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f925dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The degree 25 polynomial has the lowest RMSE on Sample 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caba92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do the same fit polynomials look on Sample 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea23c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_2, degs=[1, 3, 25], data_name='Sample 2')\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce2ddd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The degree 3 polynomial has the lowest RMSE on Sample 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f9729",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that **we didn't get to see Sample 2 when fitting our models**! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6081b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, it seems that the degree 3 polynomial **generalizes better** to unseen data than the degree 25 polynomial does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba53e71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we fit a degree 1, degree 3, and degree 25 polynomial **on Sample 2** as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_multiple_models(sample_1, sample_2, degs=[1, 3, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a9155",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: Degree 25 polynomials seem to **vary more when trained on different samples** than degree 3 and 1 polynomials do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6b397",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias and variance\n",
    "\n",
    "The training data we have access to is a sample from the population. We are concerned with our model's ability to **generalize** and work well on **different datasets** drawn from the same population.\n",
    "\n",
    "Suppose we **fit** a model $H$ (e.g. a degree 3 polynomial) on **several different datasets** from a population. There are three sources of error that arise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7a82a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ‚≠êÔ∏è **Bias**: **The expected deviation between a predicted value and an actual value**.\n",
    "    - In other words, **for a given $x_i$, how far is $H(x_i)$ from the true $y_i$, on average?**\n",
    "    - Low bias is good! ‚úÖ\n",
    "    - High bias is a sign of **underfitting**, i.e. that our model is too **basic** to capture the relationship between our features and response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec453f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ‚≠êÔ∏è **Model variance (\"variance\")**: **The variance of a model's predictions**.\n",
    "    - In other words, **for a given $x_i$, how much does $H(x_i)$ vary across all datasets**?\n",
    "    - Low model variance is good! ‚úÖ\n",
    "    - High model variance is a sign of **overfitting**, i.e. that our model is too **complicated** and is prone to fitting to the noise in our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e16e67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Observation error**: The error due to the random noise in the process we are trying to model (e.g. measurement error). _We can't control this, without collecting more data!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7857fa7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, suppose:\n",
    "- The <span style='color:#c6283f'><b>red bulls-eye</b></span> represents your **true weight and height** üßç.\n",
    "- The <span style='color:#080c6f'><b>dark blue darts</b></span> represent **predictions of your weight and height** using different models that were fit on the same DGP. \n",
    "<br>\n",
    "\n",
    "<center><img src=\"imgs/image_5.png\" width=\"40%\"></center>\n",
    "\n",
    "We'd like our models to be in the top left, but in practice that's hard to achieve!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15383fc5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Risk vs. empirical risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c4a41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DSC 40A, we started using **empirical risk minimization** to find optimal model parameters $w^*$:\n",
    "\n",
    "$$\n",
    "\\text{choose the $w$ such that } \\frac{1}{n} \\sum_{i = 1}^n \\left( y_i - H(x_i) \\right)^2 \\text{ is minimized}$$\n",
    "\n",
    "<center>or, equivalently:</center>\n",
    "\n",
    "$$w^* = \\underset{w}{\\text{argmin}} \\frac{1}{n} \\sum_{i = 1}^n \\left( y_i - H(x_i) \\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e3894",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea**: A model that works well on past data should work well on future data, if future data looks like past data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65db6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What we really want is for the **expected loss for a new data point $(x_{\\text{new}}, y_{\\text{new}})$, drawn from the same population as the training set, to be small**. That is, we want\n",
    "    $$\\mathbb{E}[y_{\\text{new}} - H(x_{\\text{new}})]^2$$\n",
    "    to be minimized. The quantity above is called **risk**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8ca84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What's that fancy $\\mathbb{E}$? It is the **expectation** operator of a random variable: it computes the **average value** of the random variable across its entire distribution.\n",
    "    - (From Math 183/180A) If $X \\sim \\text{Binomial}(n, p)$, then $\\mathbb{E}[X] = np$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4505e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, we don't know the entire population distribution of $x$s and $y$s, so we can't compute risk exactly. That's why we compute **empirical risk**!\n",
    "\n",
    "$$\\mathbb{E}[y_{\\text{new}} - H(x_{\\text{new}})]^2 \\approx \\frac{1}{n} \\sum_{i = 1}^n \\left( y_i - H(x_i) \\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce39c78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The bias-variance decomposition\n",
    "\n",
    "Risk can be decomposed as follows:\n",
    "\n",
    "$$\\mathbb{E}[y_{\\text{new}} - H(x_{\\text{new}})]^2 = \\text{model bias}^2 + \\text{model variance} + \\text{observation error}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38435d86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember, this expectation $\\mathbb{E}$ is over the entire population of $x$s and $y$s: in real life, we don't know what this population distribution is, so we can't put actual numbers to this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd04bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $H$ is too simple to capture the relationship between $x$s and $y$s in the population, $H$ will **underfit** to training sets and have **high bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25143b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $H$ is overly complex, $H$ will **overfit** to training sets and have **high variance**, meaning it will change significantly from one training set to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06760",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generally:\n",
    "    - Training error reflects bias, **not variance**.\n",
    "    - Test error reflects **both bias and variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb3f02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Navigating the bias-variance tradeoff\n",
    "\n",
    "$$\\mathbb{E}[y_{\\text{new}} - H(x_{\\text{new}})]^2 = \\text{model bias}^2 + \\text{model variance} + \\text{observation error}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ac6aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we collect more data points (i.e. as $n \\uparrow$):\n",
    "    - Model variance decreases.\n",
    "    - If $H$ can exactly model the true population relationship between $x$ and $y$ (e.g. cubic), then model bias also decreases.\n",
    "    - If $H$ can't exactly model the true population relationship between $x$ and $y$, then model bias will remain large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4fff9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we add more features (i.e. as $d \\uparrow$):\n",
    "    - Model variance increases, whether or not the feature was useful.\n",
    "    - Adding a useful feature decreases model bias.\n",
    "    - Adding a useless feature doesn't change model bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c261d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: suppose the actual relationship between $x$ and $y$ in the population is linear, and we fit $H$ using simple linear regression.\n",
    "    - Model bias = 0.\n",
    "    - Model variance $\\propto \\frac{d}{n}$.\n",
    "        - As $d \\uparrow$, model variance $\\uparrow$.\n",
    "        - As $n \\uparrow$, model variance $\\downarrow$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5276ca6",
   "metadata": {},
   "source": [
    "Read more [here](https://learningds.org/ch/17/inf_pred_gen_prob.html#probability-behind-model-selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c004c65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c8997",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train-test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa9209",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Avoiding overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e79f8e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We won't know whether our model has **overfit** to our sample (training data) unless we get to see how well it performs on a new sample from the same population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba738e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üí°**Idea**: **Split** our sample into a **training set** and **test set**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055abc38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use **only** the training set to fit the model (i.e. find $w^*$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f695a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use the test set to evaluate the model's error (RMSE, $R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbca066",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The test set is like a new sample of data from the same population as the training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa41550",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/train-test.png\" width='50%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f6da3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train-test split üöÜ\n",
    "\n",
    "`sklearn.model_selection.train_test_split` implements a train-test split for us! üôèüèº "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5e8c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If `X` is an array/DataFrame of features and `y` is an array/Series of responses,\n",
    "\n",
    "```py\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "```\n",
    "\n",
    "randomly splits the features and responses into training and test sets, such that the test set contains 0.25 of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9f895",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documentation!\n",
    "train_test_split?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf97327",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's perform a train/test split on our `tips` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0abdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips.drop('tip', axis=1)\n",
    "y = tips['tip']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # We don't have to choose 0.25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e98b61",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before proceeding, let's check the sizes of `X_train` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows in X_train:', X_train.shape[0])\n",
    "display(X_train.head())\n",
    "print('Rows in X_test:', X_test.shape[0])\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f2b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape[0] / tips.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fc207",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example train-test split\n",
    "\n",
    "Steps:\n",
    "1. Fit a model on the training set.\n",
    "2. Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips[['total_bill', 'size']] # For this example, we'll use just the already-quantitative columns in tips.\n",
    "y = tips['tip']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # random_state is like np.random.seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e38d01",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, we'll use a stand-alone `LinearRegression` model without a `Pipeline`, but this process would work the same if we were using a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9219685",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's check our model's performance on the **training** set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18894cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lr.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20d459",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And the **test** set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = lr.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c22c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since `rmse_train` and `rmse_test` are similar, it **doesn't seem like our model is overfitting** to the training data. If `rmse_test` was much larger than `rmse_train`, it would be evidence that our model is unable to **generalize well**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176323a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b338d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Polynomial regression\n",
    "\n",
    "We recently looked at an example of **polynomial regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_2, degs=[1, 3, 25], data_name='Sample 2')\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a671d7",
   "metadata": {},
   "source": [
    "When building these models:\n",
    "- We **got to choose** the degree of the polynomials (i.e. we chose 1, 3, and 25).\n",
    "- We didn't get to choose the exact formulas for the three polynomials ‚Äì their formulas were **learned from data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0e314",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters vs. hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7d0c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **parameter** defines the relationship between variables in a model. \n",
    "    - **We learn parameters from data**.\n",
    "    - For instance, suppose we fit a degree 3 polynomial to data, and end up with\n",
    "    \n",
    "    $$H(x) = 1 - 2x + 13x^2 - 4x^3$$\n",
    "    \n",
    "    - 1, -2, 13, and -4 are parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778dd62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **hyperparameter** is a parameter that we get to choose **before our model is fit to the data**.\n",
    "    - Think of hyperparameters as knobs üéõ ‚Äì **we get to pick and tune them!**\n",
    "    - **Polynomial degree** was a hyperparameter in the previous example, and we tried three different values: 1, 3, and 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1dfbc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we choose the \"right\" hyperparameter(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f97b99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2e40f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We know that a model's performance on a **test set** is a good estimate of its ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bc6c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to find the hyperparameter that leads to the best **test set performance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e28be9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Idea:\n",
    "    1. Come up with a **list** of hyperparameters to try.\n",
    "    2. For each hyperparameter, train the model on the training set and compute its performance on the test set.\n",
    "    3. Pick the hyperparameter with the best performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31001a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error\n",
    "\n",
    "- Let's try this strategy on Sample 1 from our earlier example. \n",
    "\n",
    "- We'll try to fit a polynomial model on the dataset; we'll choose the polynomial's degree from the list [1, 2, ..., 25]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c1eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we perform a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_1[['x']]\n",
    "y = sample_1['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802b8d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí° Pro-Tip: Using `make_pipeline`\n",
    "\n",
    "Instead of using the `Pipeline` class directly, you can use `make_pipeline` for a more compact syntax:\n",
    "\n",
    "(Also, there's an analogous `sklearn.compose.make_column_transformer` for the `ColumnTransformer` class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with degree-2 polynomial features\n",
    "pl = Pipeline([('poly', PolynomialFeatures(2)), ('lin-reg', LinearRegression())])\n",
    "\n",
    "# Same pipeline, notice that make_pipeline generates names for pipeline steps\n",
    "pl = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff996",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial degree vs. train/test error\n",
    "\n",
    "Now, we'll create models with degree-1 through degree-25 polynomial features and compute their train and test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "for d in range(1, 26):\n",
    "    pl = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    pl.fit(X_train, y_train)\n",
    "    train_errs.append(mean_squared_error(y_train, pl.predict(X_train), squared=False))\n",
    "    test_errs.append(mean_squared_error(y_test, pl.predict(X_test), squared=False))\n",
    "\n",
    "errs = pd.DataFrame({'Train Error': train_errs, 'Test Error': test_errs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06ac65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the plots of training error vs. degree and test error vs. degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(errs)\n",
    "fig.update_layout(showlegend=True, xaxis_title='Polynomial Degree', yaxis_title='RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dfbf6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Training error appears to decrease as polynomial degree increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724335d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Test error appears to decrease until a \"valley\", and then increases again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e0bee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, we'd choose a degree of 3, since that degree has the **lowest test error**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abe896",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error\n",
    "\n",
    "The pattern we saw in the previous example is true more generally.\n",
    "\n",
    "<center><img src='imgs/tt-errors.png' width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728db66",
   "metadata": {},
   "source": [
    "We pick the hyperparameter(s) at the \"valley\" of test error.\n",
    "\n",
    "Note that training error **tends** to underestimate test error, but it doesn't have to ‚Äì i.e., it is possible for test error to be lower than training error (say, if the test set is \"easier\" to predict than the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bc281",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conducting train-test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88811055",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall, <span style='color: blue'><b>training data</b></span> is used to fit our model, and <span style='color: orange'><b>test data</b></span> is used to evaluate our model.\n",
    "\n",
    "<center><img src='imgs/train-test-first.png' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6b2ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: _How_ should we split?\n",
    "    - `sklearn`'s `train_test_split` splits **randomly**, which usually works well.\n",
    "    - However, if there is some element of **time** in the training data (say, when predicting the future price of a stock), a better split is \"past\" and \"future\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1df4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How _large_ should the split be, e.g. 90%-10% vs. 75%-25%?\n",
    "    - There's a tradeoff ‚Äì a larger training set should lead to a \"better\" model, while a larger test set should lead to a better estimate of our model's ability to generalize.\n",
    "    - There's no \"right\" choice, but we usually choose between 10% to 25% for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf0394",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But wait..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c19ac8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- With our current strategy, we are choosing the hyperparameter that creates the model that **performs best on the test set**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427cc42",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we are **overfitting to the test set** ‚Äì the best hyperparameter for the test set might not be the best hyperparameter for a totally unseen dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01584eef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It seems like we need **another** split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa13de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4934626",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- We want to build models that generalize well to unseen data.\n",
    "    - Models that have **high bias** are **too simple** to represent complex relationships in data, and **underfit**.\n",
    "    - Models that have **high variance** are **overly complex** for the relationships in the data, and vary a lot when fit on different datasets. Such models **overfit** to the training data.\n",
    "- A model's training error tends to decrease as model complexity increases, while its test error tends to decrease, before reaching a \"sweet spot\" and increasing again.\n",
    "- A hyperparameter is a configuration that we choose before training a model; an important task in machine learning is selecting \"good\" hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9c25c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "We can't choose model hyperparameters just by using a train-test split, because this strategy overfits to the test data.\n",
    "\n",
    "Is there a better way to choose model hyperparameters? **Yes: cross-validation**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
