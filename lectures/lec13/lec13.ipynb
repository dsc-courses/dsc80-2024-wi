{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 13 ‚Äì Linear Regression\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- The Project 3 Checkpoint is due **today**.\n",
    "    - The full project is due on **Thursday, February 29th**.\n",
    "- Lab 7 is due on **Monday, February 26th**.\n",
    "- Project 4 will likely be released over the weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0499e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Come to the HDSI undergraduate social tomorrow!\n",
    "\n",
    "Diversity in Data Science (DDS) and the faculty DEI committee are jointly hosting an undergraduate social **tomorrow (Friday 2/23) from 3-5PM on the HDSI patio**.\n",
    "\n",
    "Come to socialize with your fellow classmates and faculty ‚Äì I'll be there the whole time, and so will free food!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Modeling.\n",
    "- Case study: Restaurant tips üßë‚Äçüç≥.\n",
    "- Regression in `sklearn`.\n",
    "\n",
    "Conceptually, today will mostly be review from DSC 40A, but we'll introduce a few new practical tools that we'll build upon next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271c957",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105df9d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "    \n",
    "_Taken from the Spring 2022 Final Exam._\n",
    "\n",
    "The DataFrame below contains a corpus of four song titles, labeled from 0 to 3.\n",
    "\n",
    "| | track_name |\n",
    "|---|---|\n",
    "|0| i hate you i love you i hate that i love you |\n",
    "|1| love me like a love song |\n",
    "|2| love you better |\n",
    "|3| hate sosa |\n",
    "\n",
    "**Part 1**: What is the TF-IDF of the word `\"hate\"` in Song 0's title? Use base 2 in your logarithm, and give your answer as a simplified fraction.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0938f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "\n",
    "**Part 2**: Which word in Song 0's title has the highest TF-IDF?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36491385",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "\n",
    "**Part 3**: Let $\\text{tfidf}(t, d)$ be the TF-IDF of term $t$ in document\n",
    "$d$, and let $\\text{bow}(t, d)$ be the number of occurrences of term $t$\n",
    "in document $d$.\n",
    "\n",
    "**Select all** correct answers below.\n",
    "\n",
    "- If $\\text{tfidf}(t, d) = 0$, then $\\text{bow}(t, d) = 0$.\n",
    "- If $\\text{bow}(t, d) = 0$, then $\\text{tfidf}(t, d) = 0$.\n",
    "- Neither of the above statements are necessarily true.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac9755",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "\n",
    "**Part 4**: Below, we've encoded the corpus from the previous page using the bag-of-words model.\n",
    "\n",
    "<center><img src=\"https://practice.dsc80.com/assets/images/sp22-final/bag-words.png\" width=400></center>\n",
    "\n",
    "Note that in the above DataFrame, each row has been normalized to have a\n",
    "length of 1 (i.e. $|\\vec{v}| = 1$ for all four row vectors).\n",
    "\n",
    "Which song's title has the highest cosine similarity with Song 0's\n",
    "title?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c279906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5929c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection\n",
    "\n",
    "So far this quarter, we've learned how to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0a1ae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extract information from tabular data using `pandas` and regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91c593",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Clean data so that it best represents an underlying data generating process.\n",
    "    - Missingness analyses and imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec99f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Collect data from the internet through scraping and APIs, and parse it using BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3e297",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Perform exploratory data analysis through aggregation, visualization, and the computation of summary statistics like TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc213914",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Infer about the relationships between samples and populations through hypothesis and permutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7310eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Now, let's make predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa921c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/ds-lifecycle.svg' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cdcff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b276e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **A model is a set of assumptions about how data were generated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f65868",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- George Box, a famous statistician, once said \"All models are wrong, but some are useful.\" What did he mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c66ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea0d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> \"It has been said that \"all models are wrong but some models are useful.\" In other words, any model is at best a useful fiction‚Äîthere never was, or ever will be, an exactly normal distribution or an exact linear relationship. Nevertheless, enormous progress has been made by entertaining such fictions and using them as approximations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787726d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> \"Since all models are wrong the scientist cannot obtain a \"correct\" one by excessive elaboration. On the contrary following William of Occam he should **seek an economical description of natural phenomena**. Just as the ability to devise simple but evocative models is the signature of the great scientist so overelaboration and overparameterization is often the mark of mediocrity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d209c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goals of modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f091278",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. To make accurate **predictions** regarding **unseen data**.\n",
    "\n",
    "    - Given this dataset of past UCSD data science students' salaries, can we predict your future salary? (regression)\n",
    "    - Given this dataset of images, can we predict if this new image is of a dog, cat, or zebra? (classification)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7196ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. To make **inferences** about complex phenomena in nature.\n",
    "\n",
    "    - Is there a linear relationship between the heights of children and the heights of their biological mothers?\n",
    "    - The weights of smoking and non-smoking mothers' babies babies in my _sample_ are different ‚Äì how _confident_ am I that this difference exists in the _population_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a0b01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/ml-taxonomy.svg' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6bfbe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Of the two focuses of models, we will focus on **prediction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17359bce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the above taxonomy, we will focus on **supervised learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b46afd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll start with **regression** before moving to classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397636e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910d9df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **feature** is a measurable property of a phenomenon being observed.\n",
    "    - Other terms for \"feature\" include \"(explanatory) variable\" and \"attribute\".\n",
    "    - Typically, features are the _inputs_ to models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845bcd2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DataFrames, features typically correspond to **columns**, while rows typically correspond to different individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f51147",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some features come as part of a dataset, e.g. weight and height, but others we need to create given existing features, for example:\n",
    "$$\\text{BMI} = \\frac{\\text{weight (kg)}}{\\text{[height (m)]}^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23825b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: TF-IDF creates **features** that summarize documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Restaurant tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff409ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About the data\n",
    "\n",
    "What features does the dataset contain? Is this likely a recent dataset, or an older one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72476546",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly!\n",
    "tips = px.data.tips()\n",
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63ac84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eeee3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Given various information about a table at a restaurant, we want to predict the **tip** that a server will earn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b75c1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Why** might a server be interested in doing this?\n",
    "    - To determine which tables are likely to tip the most (inference).\n",
    "    - To predict earnings over the next month (prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cd857",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7bcfee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most natural feature to look at first is total bills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1f389",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we should explore the relationship between total bills and tips. Moving forward:\n",
    "    - $x$: Total bills.\n",
    "    - $y$: Tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100b81c",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = tips.plot(kind='scatter', x='total_bill', y='tip', title='Tip vs. Total Bill')\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ef9bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #1: Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce733b6d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's start simple, by ignoring all features. Suppose our model assumes every tip is given by a constant dollar amount:\n",
    "\n",
    "$$\\text{tip} = h^{\\text{true}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5a809",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Model**: There is a single tip amount $h^{\\text{true}}$ that all customers pay.\n",
    "    - Correct? No!\n",
    "    - Useful? Perhaps. An estimate of $h^{\\text{true}}$, denoted by $h^*$, can allow us to predict future tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a3c6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/constant-convo.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc3074",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating $h^{\\text{true}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0468783",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The true **parameter** $h^{\\text{true}}$ is determined by the universe. We'll never get to see it, so we need to **estimate** it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecec48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are several ways we _could_ estimate $h^{\\text{true}}$. For instance, we _could_ use domain knowledge: for instance, assume that everyone clicks the \\$1 tip option when buying coffee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b8ba7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, perhaps, we should look at the tips that we've already seen in our dataset to estimate $h^{\\text{true}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48cfeb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking at the data\n",
    "\n",
    "Our estimate for $h^{\\text{true}}$ should be a good **summary statistic** of the distribution of tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tips.plot(kind='hist', x='tip', title='Distribution of Tip', nbins=20)\n",
    "fig.update_layout(xaxis_title='Tip', yaxis_title='Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ebdca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical risk minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a1cbd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DSC 40A, we established a framework for estimating model parameters:\n",
    "    - **Choose a loss function**, which measures how \"good\" a single prediction is.\n",
    "    - **Minimize empirical risk**, to find the best estimate for the dataset that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba59d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Depending on which loss function we choose, we will end up with different $h^*$ (which are estimates of $h^{\\text{true}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2daae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we choose **squared loss**, then our empirical risk is **mean squared error**:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i = 1}^n ( y_i - h )^2 \\overset{\\text{calculus}}\\implies h^* = \\text{mean}(y)$$\n",
    "\n",
    "<center>\n",
    "<small markdown=\"1\">Remember, tips are our $y$ variable.</small>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf6927",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we choose **absolute loss**, then our empirical risk is **mean absolute error**:\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i = 1}^n | y_i - h | \\overset{\\text{algebra}}\\implies h^* = \\text{median}(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c7e4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The mean tip\n",
    "\n",
    "Let's suppose we choose squared loss, meaning that $h^* = \\text{mean}(y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tip = tips['tip'].mean()\n",
    "mean_tip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7925a3f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$h^* = 2.998$ is our **fit model** ‚Äì it was fit to our **training data** (the data we have available to learn from)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682f5f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's visualize this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tips, x='total_bill', y='tip')\n",
    "fig.add_hline(mean_tip, line_width=3, line_color='orange', opacity=1)\n",
    "fig.update_layout(title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8029d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that to make predictions, this model ignores total bill (and all other features), and predicts the same tip for all tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3d4b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The quality of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fcd1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How can we quantify how **good** this constant prediction is at predicting tips in our **training data** ‚Äì that is, the data we used to **fit** the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de4c256",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One answer**: use the mean squared error. If $y_i$ represents the $i$th actual value and $H(x_i)$ represents the $i$th predicted value, then:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((tips['tip'] - mean_tip) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same! A fact from 40A.\n",
    "np.var(tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216250ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Issue: The units of MSE are \"dollars squared\", which are a little hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308abe7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163c1ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Often, to measure the quality of a regression model's predictions, we will use the **root mean squared error (RMSE)**:\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2c048",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The units of the RMSE are the same as the units of the original $y$ values ‚Äì dollars, in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328798f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: Minimizing MSE is the same as minimizing RMSE; the constant tip $h^*$ that minimizes MSE is the same $h^*$ that minimizes RMSE. (Why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c5b96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing and storing the RMSE\n",
    "\n",
    "Since we'll compute the RMSE for our future models too, we'll define a function that can compute it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2e2e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's compute the RMSE of our constant tip's predictions, and store it in a dictionary that we can refer to later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(tips['tip'], mean_tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c532f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: Since the mean minimizes RMSE for the constant model, it is **impossible** to change the `mean_tip` argument above to another number and yield a **lower** RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7735c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7060d61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #2: Simple linear regression using total bill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07250734",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We haven't yet used any of the **features** in the dataset. The first natural feature to look at is `'total_bill'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b073ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e44983",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can fit a **simple linear model** to predict tips as a function of total bills:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ddfca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is a reasonable thing to do, because total bills and tips appeared to be linearly associated when we visualized them on a scatter plot a few slides ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382ee3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Simple linear regression\n",
    "\n",
    "A simple linear regression model is a linear model with a single feature, as we have here. For any total bill $x_i$, the predicted tip $H(x_i)$ is given by\n",
    "\n",
    "$$H(x_i) = w_0 + w_1x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c0ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we determine which intercept, $w_0$, and slope, $w_1$, to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b073af3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One answer**: Pick the $w_0$ and $w_1$ that minimize **mean squared error**. If $x_i$ and $y_i$ correspond to the $i$th total bill and tip, respectively, then:\n",
    "\n",
    "$$\\begin{align*}\\text{MSE} &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2\n",
    "\\\\ &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - w_0 - w_1x_i \\big)^2\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c3462",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea: The lower the MSE on our training data is, the \"better\" the model fits the training data**.\n",
    "    - Lower MSE = better **predictions**.\n",
    "    - But lower MSE ‚â† more reflective of reality!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c5f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical risk minimization, by hand\n",
    "\n",
    "$$\\begin{align*}\\text{MSE} &= \\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - w_0 - w_1x_i \\big)^2\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33958db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In DSC 40A, you found the formulas for the best intercept, $w_0^*$, and the best slope, $w_1^*$, through calculus. \n",
    "    - The resulting line, $H(x_i) = w_0^* + w_1^* x_i$, is called the **line of best fit**, or the **regression line**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4896904",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Specifically, if $r$ is the correlation coefficient, $\\sigma_x$ and $\\sigma_y$ are the standard deviations of $x$ and $y$, and $\\bar{x}$ and $\\bar{y}$ are the means of $x$ and $y$, then:\n",
    "\n",
    "$$w_1^* = r \\cdot \\frac{\\sigma_y}{\\sigma_x}$$\n",
    "\n",
    "$$w_0^* = \\bar{y} - w_1^* \\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8922bec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ed0be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `sklearn`\n",
    "\n",
    "<center><img src='imgs/sklearn.png' width=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace2eed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` (scikit-learn) implements many common steps in the feature and model creation pipeline.\n",
    "    - It is **widely** used throughout [industry](https://scikit-learn.org/stable/testimonials/testimonials.html#:~:text=It%20is%20very%20widely%20used,very%20approachable%20and%20very%20powerful.) and academia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7241330",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It interfaces with `numpy` arrays, and to an extent, `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d503e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Huge benefit: the [documentation online](https://scikit-learn.org/stable/modules/classes.html) is excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0279c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `LinearRegression` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff00f7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` comes with several subpackages, including `linear_model` and `tree`, each of which contains several classes of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887214d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll start with the `LinearRegression` class from `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5fb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ec61c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Important**: From [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression), we have:\n",
    "> LinearRegression fits a linear model with coefficients w = (w1, ‚Ä¶, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "\n",
    "    In other words, **`LinearRegression` minimizes mean squared error by default**! (Per the documentation, it also includes an intercept term by default.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17553ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d6df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55feff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we must instantiate a `LinearRegression` object and fit it. By calling `fit`, we are saying \"minimize mean squared error on this dataset and find $w^*$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Note that there are two arguments to fit ‚Äì X and y!\n",
    "# (It is not necessary to write X= and y=)\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983b9bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After fitting, we can access $w^*$ ‚Äì that is, the best slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_, model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05170d2f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These coefficients tell us that the \"best way\" (according to squared loss) to make tip predictions using a linear model is using:\n",
    "\n",
    "$$\\text{predicted tip} = 0.92 + 0.105 \\cdot \\text{total bill}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0bde1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This model **predicts** that people tip by:\n",
    "- Tipping a constant 92 cents.\n",
    "- Tipping 10.5\\% for every dollar spent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f892e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the best \"linear\" pattern in the dataset ‚Äì it doesn't mean this is actually how people tip!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad774c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize this model, along with our previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0171c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pts = pd.DataFrame({'total_bill': [0, 60]})\n",
    "\n",
    "fig = px.scatter(tips, x='total_bill', y='tip')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=line_pts['total_bill'],\n",
    "    y=[mean_tip, mean_tip],\n",
    "    mode='lines',\n",
    "    name='Constant Model (Mean Tip)'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=line_pts['total_bill'],\n",
    "    y=model.predict(line_pts),\n",
    "    mode='lines',\n",
    "    name='Linear Model: Total Bill Only'\n",
    "))\n",
    "fig.update_layout(title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', \n",
    "                  yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1d94a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Visually, our linear model _seems_ to be a better fit for our dataset than our constant model.\n",
    "\n",
    "Can we quantify whether or not it is better? **Does it better reflect reality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776c605",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions\n",
    "\n",
    "Fit `LinearRegression` objects also have a `predict` method, which can be used to predict tips for any total bill, new or old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we trained on a DataFrame, the input to model.predict should also\n",
    "# be a DataFrame. To avoid having to do this, we can use .to_numpy()\n",
    "# when specifying X= and y=.\n",
    "test_points = pd.DataFrame({'total_bill': [15, 4, 100]})\n",
    "model.predict(test_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc0fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing models\n",
    "\n",
    "If we want to compute the RMSE of our model on the training data, we need to find its predictions on every row in the training data, `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3483d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = model.predict(tips[['total_bill']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d84da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319bc0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The RMSE of our simple linear model is **lower** than that of our constant model, which means it does a **better job** at predicting tips in our training data than our constant model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ad18f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Theory tells us it's impossible for the RMSE **on the training data** to increase as we add more features to the same model. However, the RMSE may increase on **unseen data** by adding more features; we'll discuss this idea more soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba7387",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037400cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #3: Multiple linear regression using total bill and table size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c49b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are still many features in `tips` we haven't touched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb05d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd72f28",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try using another feature ‚Äì table size. Such a model would predict tips using:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b57e40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple linear regression\n",
    "\n",
    "To find the optimal parameters $w^*$, we will again use `sklearn`'s `LinearRegression` class. The code is not all that different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce651f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ab753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.intercept_, model_two.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e18991",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pts = pd.DataFrame({'total_bill': [25], 'size': [4]})\n",
    "model_two.predict(test_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6967c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What does this model _look_ like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9f722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plane of best fit ‚úàÔ∏è\n",
    "\n",
    "Here, we must draw a 3D scatter plot and plane, with one axis for total bill, one axis for table size, and one axis for tip. The code below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z = model_two.intercept_ + model_two.coef_[0] * XX + model_two.coef_[1] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z, colorscale='Oranges')\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=tips['total_bill'], \n",
    "                           y=tips['size'], \n",
    "                           z=tips['tip'], mode='markers', marker = {'color': '#656DF1'}))\n",
    "\n",
    "fig.update_layout(scene=dict(xaxis_title='Total Bill',\n",
    "                             yaxis_title='Table Size',\n",
    "                             zaxis_title='Tip'),\n",
    "                  title='Tip vs. Total Bill and Table Size',\n",
    "                  width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ffbb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing models, again \n",
    "\n",
    "How does our two-feature linear model stack up to our single feature linear model and our constant model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f85ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The RMSE of our two-feature model is the lowest of the three models we've looked at so far, but not by much. We didn't **gain** much by adding table size to our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b50098",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's also not clear whether table sizes are practically useful in predicting tips.\n",
    "    - We already have the total amount the table spent; why do we need to know how many people were there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7f997",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397b09b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- From DSC 10: one important technique for diagnosing model fit is the **residual plot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f966a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $i$th residual is $ y_i - H(x_i) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d890bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A residual plot has\n",
    "    - **predicted values $H(x)$** on the $x$-axis, and\n",
    "    - **residuals $ y - H(x) $** on the $y$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the single-variable model:\n",
    "with_resid = tips.assign(**{\n",
    "    'Predicted Tip': model.predict(tips[['total_bill']]),\n",
    "    'Residual': tips['tip'] - model.predict(tips[['total_bill']]),\n",
    "})\n",
    "fig = px.scatter(with_resid, x='Predicted Tip', y='Residual')\n",
    "fig.add_hline(0, line_width=2, opacity=1).update_layout(title='Residual Plot (Simple Linear Model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cb510",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If all assumptions about linear regression hold, then residual plot should look randomly scattered around the horizontal line $y = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e8ea5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, we see that the model makes bigger mistakes for larger predicted values. But overall, there's no apparent trend, so a linear model seems appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f0ff1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# What about the two-variable model?\n",
    "with_resid = tips.assign(**{\n",
    "    'Predicted Tip': model_two.predict(tips[['total_bill', 'size']]),\n",
    "    'Residual': tips['tip'] - model_two.predict(tips[['total_bill', 'size']]),\n",
    "})\n",
    "fig = px.scatter(with_resid, x='Predicted Tip', y='Residual')\n",
    "fig.add_hline(0, line_width=2, opacity=1).update_layout(title='Residual Plot (Multiple Regression)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec8e1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looks about the same as the previous plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4f03b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ae07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.score` method of a `LinearRegression` object\n",
    "\n",
    "Model objects in `sklearn` that have already been fit have a `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bd253",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That doesn't look like the RMSE... what is it? ü§î\n",
    "\n",
    "We'll find out next time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159950e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaa978",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- We built three models:\n",
    "    - A constant model: $\\text{predicted tip} = h^*$.\n",
    "    - A simple linear regression model: $\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill}$.\n",
    "    - A multiple linear regression model: $\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill} + w_2^* \\cdot \\text{table size}$.\n",
    "- As we added more features, our RMSEs decreased.\n",
    "    - This was guaranteed to happen, since we were only looking at our training data.\n",
    "- It is not clear that the final linear model is actually \"better\"; it doesn't seem to **reflect reality** better than the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3dd70c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LinearRegression` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(X, y)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(X_new)`| Uses regression line to make predictions|\n",
    "|Evaluate the model| `lr.score(X, y)` | Calculates the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_`, `lr.intercept_` | Accesses the regression coefficients and intercept|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153988b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, in our journey to predict `'tip'`, we've only used the existing numerical features in our dataset, `'total_bill'` and `'size'`.\n",
    "\n",
    "- There's a lot of information in tips that we didn't use ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'`, for example. We can't use these features in their current form, because they're non-numeric.\n",
    "\n",
    "- **How do we use categorical features in a regression model?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
