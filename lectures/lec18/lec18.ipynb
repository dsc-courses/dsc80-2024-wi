{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 18 ‚Äì Classifier Evaluation, Model Fairness\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- [Project 4](https://dsc80.com/proj04) is due on **Thursday, March 21st**.\n",
    "    - **No slip days allowed!**\n",
    "- The Final Exam is on **Tuesday, March 19th from 3-6PM** (room TBD).\n",
    "    - Practice by working through old exams at [practice.dsc80.com](https://practice.dsc80.com).\n",
    "    - You can bring two double-sided notes sheets (you can bring your midterm notes sheet, if you want).\n",
    "    - Check Ed for more details.\n",
    "- If at least 80% of the class fills out both [**SETs**](https://academicaffairs.ucsd.edu/Modules/Evals/) and the [**End-of-Quarter Survey**](https://docs.google.com/forms/d/e/1FAIpQLSe-ADKrha3WLbf1U6mrwxxy7hckSHCsMJfNjs53AoPP0LJABg/viewform) by **Saturday, March 16th at 8AM**, then we will add 1% of extra credit to everyone's overall grade.\n",
    "- Thursday's class will be entirely exam review!\n",
    "    - I'll look at the topics you mentioned in the Discussion 9 form to decide which old exam problems to cover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1b3ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Classifier evaluation.\n",
    "- Logistic regression.\n",
    "- Model fairness.\n",
    "\n",
    "Aside: [MLU Explain](https://mlu-explain.github.io/) is a **great** resource with visual explanations of many of our recent topics (cross-validation, random forests, precision and recall, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3da1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e9f87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision and recall\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{TP + FP} \\: \\: \\: \\:  \\: \\: \\: \\: \\text{recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb905e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ü§î **Question**: When might high **precision** be more important than high recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cdd52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**üôã Answer**: For instance, in deciding whether or not someone committed a crime. Here, **false positives are really bad** ‚Äì they mean that an innocent person is charged!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363fa499",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ü§î **Question**: When might high **recall** be more important than high precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce282db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**üôã Answer**: For instance, in medical tests. Here, **false negatives are really bad** ‚Äì they mean that someone's disease goes undetected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304b7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "<h3>Exercise</h3>\n",
    "\n",
    "_Taken from the Spring 2022 Final Exam._\n",
    "\n",
    "After fitting our `BillyClassifier` from the previous question, we use it to make predictions on an unseen test set. Our results are summarized in the following confusion matrix.\n",
    "\n",
    "| | **Predicted Negative** | **Predicted Positive** |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | ??? | 30 |\n",
    "| **Actually Positive** | 66 | 105 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c51369",
   "metadata": {},
   "source": [
    "**Part 1**: What is the recall of our classifier? Give your answer as a fraction (it does not need to be simplified)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f2082",
   "metadata": {},
   "source": [
    "**Part 2**: The accuracy of our classifier is $\\frac{69}{117}$. How many **true negatives** did our classifier have? Give your answer as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59eb5fe",
   "metadata": {},
   "source": [
    "**Part 3**: True or False: In order for a binary classifier's precision and recall to be equal, the number of mistakes it makes must be an even number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c092826",
   "metadata": {},
   "source": [
    "**Part 4**: Suppose we are building a classifier that listens to an audio source (say, from your phone‚Äôs microphone) and predicts whether or not it is Soulja Boy‚Äôs 2008 classic ‚ÄúKiss Me thru the Phone.\" Our classifier is pretty good at detecting when the input stream is ‚ÄùKiss Me thru the Phone\", but it often incorrectly predicts that similar sounding songs are also ‚ÄúKiss Me thru the Phone.\"\n",
    "\n",
    "Complete the sentence: Our classifier has...\n",
    "- low precision and low recall.\n",
    "- low precision and high recall.\n",
    "- high precision and low recall.\n",
    "- high precision and high recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc7931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80f041",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wisconsin breast cancer dataset\n",
    "\n",
    "The Wisconsin breast cancer dataset (WBCD) is a commonly-used dataset for demonstrating binary classification. It is built into `sklearn.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1145e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "loaded = load_breast_cancer() # explore the value of `loaded`!\n",
    "data = loaded['data']\n",
    "labels = 1 - loaded['target']\n",
    "cols = loaded['feature_names']\n",
    "bc = pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa367d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710aa827",
   "metadata": {},
   "source": [
    "1 stands for \"malignant\", i.e. cancerous, and 0 stands for \"benign\", i.e. safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241acd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9596e",
   "metadata": {},
   "source": [
    "Our goal is to use the features in `bc` to predict `labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e76be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression\n",
    "\n",
    "Logistic _regression_ is a linear _classification_ technique that builds upon linear regression. It models **the probability of belonging to class 1, given a feature vector**:\n",
    "\n",
    "$$P(y = 1 | \\vec{x}) = \\sigma (\\underbrace{w_0 + w_1 x^{(1)} + w_2 x^{(2)} + ... + w_d x^{(d)}}_{\\text{linear regression model}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787027bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, $\\sigma(t) = \\frac{1}{1 + e^{-t}}$ is the **sigmoid** function; its outputs are between 0 and 1 (which means they can be interpreted as probabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6617f05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ü§î **Question**: Suppose our logistic regression model predicts the probability that a tumor is malignant is 0.75. What class do we predict ‚Äì malignant or benign? What if the predicted probability is 0.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb6ec8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üôã **Answer**: We have to pick a threshold (e.g. 0.5)!\n",
    "- If the predicted probability is above the threshold, we predict malignant (1).\n",
    "- Otherwise, we predict benign (0).\n",
    "- In practice, we use cross validation to decide this threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3887f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e32901",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6486deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7672cba",
   "metadata": {},
   "source": [
    "How did `clf` come up with 1s and 0s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae4b20",
   "metadata": {},
   "source": [
    "It turns out that the predicted labels come from applying a **threshold** of 0.5 to the predicted probabilities. We can access the predicted probabilities using the `predict_proba` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [:, 1] refers to the predicted probabilities for class 1.\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18585288",
   "metadata": {},
   "source": [
    "Note that our model still has $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a20536",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eccc315",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating our model\n",
    "\n",
    "Let's see how well our model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f581932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3df1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f6b3e",
   "metadata": {},
   "source": [
    "Which metric is more important for this task ‚Äì precision or recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee157da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test);\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b440311",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f392d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if we choose a different threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1e787",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ü§î **Question**: Suppose we choose a threshold **higher** than 0.5. What will happen to our model's precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9f2ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üôã **Answer**: Precision will increase, while recall will decrease*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d59c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the \"bar\" is higher to predict 1, then we will have fewer positives in general, and thus fewer false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3a66e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The denominator in $\\text{precision} = \\frac{TP}{TP + FP}$ will get smaller, and so precision will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab1dee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, the number of false negatives will increase, as we are being more \"strict\" about what we classify as positive, and so $\\text{recall} = \\frac{TP}{TP + FN}$ will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eb82e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *It is possible for either or both to stay the same, if changing the threshold slightly (e.g. from 0.5 to 0.500001) doesn't change any predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b90c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Similarly, if we decrease our threshold, our model's precision will decrease, while its recall will increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e3d78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Trying several thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6d3d6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The classification threshold is not actually a hyperparameter of `LogisticRegression`, because the threshold doesn't change the coefficients ($w^*$s) of the logistic regression model itself (see [this article](https://stats.stackexchange.com/questions/390186/is-decision-threshold-a-hyperparameter-in-logistic-regression#:~:text=The%20decision%20threshold%20is%20not,how%20hyper%2Dparameters%20are%20tuned.) for more details).\n",
    "\n",
    "- Still, the threshold affects our decision rule, so we can tune it using cross-validation (which is not what we're doing below).\n",
    "- It's also useful to plot how our metrics change as we change the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 1.01, 0.01)\n",
    "precisions = np.array([])\n",
    "recalls = np.array([])\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1] >= t\n",
    "    precisions = np.append(precisions, metrics.precision_score(y_test, y_pred, zero_division=1))\n",
    "    recalls = np.append(recalls, metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3931101",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=thresholds, y=precisions,\n",
    "        labels={'x': 'Threshold', 'y': 'Precision'}, title='Precision vs. Threshold', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ab0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=thresholds, y=recalls, \n",
    "        labels={'x': 'Threshold', 'y': 'Recall'}, title='Recall vs. Threshold', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=recalls, y=precisions, hover_name=thresholds, \n",
    "        labels={'x': 'Recall', 'y': 'Precision'}, title='Precision vs. Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e90bd5",
   "metadata": {},
   "source": [
    "The above curve is called a precision-recall (or PR) curve.\n",
    "\n",
    "ü§î **Question**: Based on the PR curve above, what threshold would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830792b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining precision and recall\n",
    "\n",
    "If we care equally about a model's precision $PR$ and recall $RE$, we can combine the two using a single metric called the **F1-score**:\n",
    "\n",
    "$$\\text{F1-score} = \\text{harmonic mean}(PR, RE) = 2\\frac{PR \\cdot RE}{PR + RE}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = metrics.precision_score(y_test, clf.predict(X_test))\n",
    "re = metrics.recall_score(y_test, clf.predict(X_test))\n",
    "\n",
    "2 * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e120d7",
   "metadata": {},
   "source": [
    "Both F1-score and accuracy are overall measures of a binary classifier's performance. But remember, accuracy is misleading in the presence of class imbalance, and doesn't take into account the kinds of errors the classifier makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9060948",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc2323",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other evaluation metrics for binary classifiers\n",
    "\n",
    "We just scratched the surface! This [excellent table from Wikipedia](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram) summarizes the many other metrics that exist.\n",
    "\n",
    "<center><img src='imgs/wiki-table.png' width=75%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac429208",
   "metadata": {},
   "source": [
    "If you're interested in exploring further, a good next metric to look at is **true negative rate (i.e. specificity)**, which is the analogue of recall for true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaaf33f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd4172",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fairness: why do we care?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be875eb2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sometimes, a model performs better for certain groups than others; in such cases we say the model is **unfair**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91ad33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since ML models are now used in processes that significantly affect human lives, it is important that they are fair!\n",
    "    * Job applications and college admissions.\n",
    "    * Criminal sentencing and parole grants.\n",
    "    * Predictive policing.\n",
    "    * Credit and loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113995c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Google's Gemini\n",
    "\n",
    "<center><img src=\"imgs/gemini.png\" width=800></center>\n",
    "\n",
    "> ...a request for ‚Äúa US senator from the 1800s‚Äù returned a list of results Gemini promoted as ‚Äúdiverse,‚Äù including what appeared to be Black and Native American women. (The first female senator, a white woman, served in 1922.) It‚Äôs a response that ends up erasing a real history of race and gender discrimination ‚Äî ‚Äúinaccuracy,‚Äù as Google puts it, is about right. ([source](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745f228",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From [_Gemini image generation got it wrong. We'll do better._](https://blog.google/products/gemini/gemini-image-generation-issue/):\n",
    "\n",
    "> If you ask for a picture of football players, or someone walking a dog, you may want to receive a range of people. You probably don‚Äôt just want to only receive images of people of just one type of ethnicity (or any other characteristic).<br><br>However, if you prompt Gemini for images of a specific type of person ‚Äî such as ‚Äúa Black teacher in a classroom,‚Äù or ‚Äúa white veterinarian with a dog‚Äù ‚Äî or people in particular cultural or historical contexts, you should absolutely get a response that accurately reflects what you ask for.<br><br>So what went wrong? In short, two things. First, our tuning to ensure that Gemini showed a range of people failed to account for cases that should clearly not show a range. And second, over time, the model became way more cautious than we intended and refused to answer certain prompts entirely ‚Äî wrongly interpreting some very anodyne prompts as sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db21b8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96f7de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'd like to build a model that is _fair_, meaning that it performs the same for individuals within a group and individuals outside of the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd476007",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do we mean by \"perform\"? What do we mean by \"the same\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1e1c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/parity.png\" width=900></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729f2d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parity measures for classifiers\n",
    "\n",
    "Suppose $C$ is a classifier we've already trained, and $A$ is some binary attribute that denotes whether an individual is a member of a _sensitive_ group ‚Äì that is, a group we want to avoid discrimination for (e.g. $A = \\text{age is less than 25}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc8898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **accuracy parity** if $C$ has the same accuracy for individuals in $A$ and individuals not in $A$.\n",
    "    - **Example**: $C$ is a binary classifier that determines whether someone receives a loan.\n",
    "        - If the classifier predicts correctly, then either $C$ approves the loan and it is paid off, or $C$ denies the loan and it would have defaulted.\n",
    "        - If $C$ achieves accuracy parity, then the proportion of correctly classified loans should be the same for those under 25 and those over 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35b231",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **precision (or recall) parity** if $C$ has the same precision (or recall) for individuals in $A$ and individuals not in $A$.\n",
    "    - Recall parity is often called \"true positive rate parity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96a662",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $C$ achieves **demographic parity** if the proportion of predictions that are positive is equal for individuals in $A$ and individuals not in $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278f32f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- With the exception of demographic parity, the parity measures above all involve checking whether some evaluation metric from Lecture 17 is equal across two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472a8e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More on parity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ac7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Which parity metric should you care about? It depends on your specific dataset and what types of errors are important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f308ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Many of these parity measures are **impossible** to satisfy simultaneously!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da27bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The classifier parity metrics mentioned on the previous slide are only a few of the many possible parity metrics. See these [DSC 167 notes](https://afraenkel.github.io/fairness-book/content/05-parity-measures.html) for more details, including more formal explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17eb52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These don't apply for regression models; for those, we may care about **RMSE parity** or **$R^2$ parity**. There is also a notion of demographic parity for regression models, but it is outside of the scope of DSC 80."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133fdef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Loan approval\n",
    "\n",
    "As you know from Project 2, LendingClub was a \"peer-to-peer lending company\"; they [used to publish](https://www.lendingclub.com/info/download-data.action) a dataset describing the loans that they approved.\n",
    "\n",
    "* `'tag'`: whether loan was repaid in full (1.0) or defaulted (0.0).\n",
    "* `'loan_amnt'`: amount of the loan in dollars.\n",
    "* `'emp_length'`: number of years employed.\n",
    "* `'home_ownership'`: whether borrower owns (1.0) or rents (0.0).\n",
    "* `'inq_last_6mths'`: number of credit inquiries in last six months.\n",
    "* `'revol_bal'`: revolving balance on borrows accounts.\n",
    "* `'age'`: age in years of the borrower (protected attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(Path('data') / 'loan_vars1.csv', index_col=0)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193ad90",
   "metadata": {},
   "source": [
    "The total amount of money loaned was over 5 billion dollars! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33148e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['loan_amnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038ba67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'tag'`\n",
    "\n",
    "Let's build a classifier that predicts whether or not a loan was paid in full. If we were a bank, we could use our trained classifier to determine whether to approve someone for a loan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb552ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans.drop('tag', axis=1)\n",
    "y = loans.tag\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c1ce4",
   "metadata": {},
   "source": [
    "Recall, a prediction of 1 means that we predict that the loan will be paid in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da802548",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78523b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d46754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test);\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367ce0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "Precision describes the **proportion of loans that were approved that would have been paid back**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738e246",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we subtract the precision from 1, we get the proportion of loans that were approved that **would not** have been paid back. This is known as the **false discovery rate**.\n",
    "\n",
    "$$\\frac{FP}{TP + FP} = 1 - \\text{precision}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8288253",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920473c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Recall describes the **proportion of loans that would have been paid back that were actually approved**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e738e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f30a3a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we subtract the recall from 1, we get the proportion of loans that would have been paid back that **were denied**. This is known as the **false negative rate**.\n",
    "\n",
    "$$\\frac{FN}{TP + FN} = 1 - \\text{recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380f3d0",
   "metadata": {},
   "source": [
    "From both the perspective of the bank and the lendee, a high false negative rate is bad!\n",
    "- The bank left money on the table ‚Äì the lendee would have paid back the loan, but they weren't approved for a loan.\n",
    "- The lendee deserved the loan, but weren't given one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca9139",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### False negative rate by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = X_test\n",
    "results['age_bracket'] = results['age'].apply(lambda x: 5 * (x // 5 + 1))\n",
    "results['prediction'] = y_pred\n",
    "results['tag'] = y_test\n",
    "\n",
    "(\n",
    "    results\n",
    "    .groupby('age_bracket')\n",
    "    .apply(lambda x: 1 - metrics.recall_score(x['tag'], x['prediction']))\n",
    "    .plot(kind='bar', title='False Negative Rate by Age Group')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac6d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing parity measures\n",
    "\n",
    "- $C$: Our random forest classifier (1 if we approved the loan, 0 if we denied it).\n",
    "- $A$: Whether or not they were under 25 (1 if under, 0 if above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['is_young'] = (results['age'] < 25).replace({True: 'young', False: 'old'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028b388",
   "metadata": {},
   "source": [
    "First, let's compute the proportion of loans that were approved in each group. If these two numbers are the same, $C$ achieves demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bda10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('is_young')['prediction'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd587f",
   "metadata": {},
   "source": [
    "$C$ evidently does not achieve demographic parity ‚Äì older people are approved for loans far more often! Note that this doesn't factor in whether they were _correctly_ approved or _incorrectly_ approved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea011ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's compute the accuracy of $C$ in each group. If these two numbers are the same, $C$ achieves accuracy parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a270863",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy = lambda x: metrics.accuracy_score(x['tag'], x['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results\n",
    "    .groupby('is_young')\n",
    "    .apply(compute_accuracy)\n",
    "    .rename('accuracy')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6cddc",
   "metadata": {},
   "source": [
    "Hmm... These numbers look much more similar than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4eb148",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Is this difference in accuracy significant?\n",
    "\n",
    "Let's run a **permutation test** to see if the difference in accuracy is significant.\n",
    "- **Null Hypothesis**: The classifier's accuracy is the same for both young people and old people, and any differences are due to chance.\n",
    "- **Alternative Hypothesis**: The classifier's accuracy is higher for old people.\n",
    "- Test statistic: Difference in accuracy (young minus old).\n",
    "- Significance level: 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = results.groupby('is_young').apply(compute_accuracy).diff().iloc[-1]\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_in_acc = []\n",
    "for _ in range(500):\n",
    "    s = (\n",
    "        results[['is_young', 'prediction', 'tag']]\n",
    "        .assign(is_young=np.random.permutation(results['is_young']))\n",
    "        .groupby('is_young')\n",
    "        .apply(compute_accuracy)\n",
    "        .diff()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    \n",
    "    diff_in_acc.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.Series(diff_in_acc).plot(kind='hist', histnorm='probability', nbins=20,\n",
    "                            title='Difference in Accuracy (Young - Old)')\n",
    "fig.add_vline(x=obs, line_color='red')\n",
    "fig.update_layout(xaxis_range=[-0.1, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b781a",
   "metadata": {},
   "source": [
    "It seems like the difference in accuracy across the two groups **is significant**, despite being only ~5%. Thus, $C$ likely does not achieve accuracy parity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e001ad2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ethical questions of fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e61db6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Is it \"fair\" to deny loans to younger people at a higher rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41537df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One answer: yes!\n",
    "    - Young people default more often.\n",
    "    - To have same level of accuracy, we need to deny them loans more often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9593ddc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Other answer: no!\n",
    "    - Accuracy isn't everything.\n",
    "    - Younger people **need** loans to buy houses, pay for school, etc.\n",
    "    - The bank should be required to take on higher risk; this is the cost of operating in a society."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd7962",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Federal law prevents age from being used as a determining factor in denying a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c030f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not only should we use `'age'` to determine whether or not to approve a loan, but we also shouldn't use other features that are strongly correlated with `'age'`, like `'emp_length'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf9bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6f965",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505b87f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- A logistic regression model makes classifications by first predicting a probability and then thresholding that probability.\n",
    "    - The default threshold is 0.5; by moving the threshold, we change the balance between precision and recall.\n",
    "- To assess the parity of your model:\n",
    "    - Choose an evaluation metric, e.g. precision, recall, or accuracy for classifiers, or RMSE or $R^2$ for regressors.\n",
    "    - Choose a sensitive binary attribute, e.g. \"age < 25\" or \"is data science major\", that divides your data into two groups.\n",
    "    - Conduct a permutation test to verify whether your model's evaluation criteria is similar for individuals in both groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8959eb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Exam review! I'll look at the topics you mentioned in the Discussion 9 form to decide which old exam problems to cover."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
