{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *\n",
    "import lec16_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 16 â€“ Hyperparameters, Cross-Validation, and Decision Trees\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements ğŸ“£\n",
    "\n",
    "- Project 4 is released! Read all about it at [**dsc80.com/proj04**](https://dsc80.com/proj04).\n",
    "    - The checkpoint is due **this Thursday**.\n",
    "    - The full project is due on **Thursday, March 21st**. You **cannot** use slip days on the final deadline.\n",
    "- Lab 9 is due on **Monday, March 11th**.\n",
    "- The Final Exam is on **Tuesday, March 19th from 3-6PM** (room TBD).\n",
    "    - Practice by working through old exams at [practice.dsc80.com](https://practice.dsc80.com). Even more exams are there now, including this quarter's midterm.\n",
    "    - You can bring two double-sided notes sheets (you can bring your midterm notes sheet, if you want).\n",
    "    - More details to come."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda ğŸ“†\n",
    "\n",
    "- Hyperparameters.\n",
    "- Cross-validation.\n",
    "- Decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74dd70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ğŸ¤” (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176323a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cfdb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # For reproducibility.\n",
    "\n",
    "def sample_from_pop(n=100):\n",
    "    x = np.linspace(-2, 3, n)\n",
    "    y = x ** 3 + (np.random.normal(0, 3, size=n))\n",
    "    return pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "sample_1 = sample_from_pop()\n",
    "sample_2 = sample_from_pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2538011",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b338d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Polynomial regression\n",
    "\n",
    "We recently looked at an example of **polynomial regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_2, degs=[1, 3, 25], data_name='Sample 2')\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a671d7",
   "metadata": {},
   "source": [
    "When building these models:\n",
    "- We **got to choose** the degree of the polynomials (i.e. we chose 1, 3, and 25).\n",
    "- We didn't get to choose the exact formulas for the three polynomials â€“ their formulas were **learned from data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0e314",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters vs. hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7d0c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **parameter** defines the relationship between variables in a model. \n",
    "    - **We learn parameters from data**.\n",
    "    - For instance, suppose we fit a degree 3 polynomial to data, and end up with\n",
    "    \n",
    "    $$H(x) = 1 - 2x + 13x^2 - 4x^3$$\n",
    "    \n",
    "    - 1, -2, 13, and -4 are parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778dd62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A **hyperparameter** is a parameter that we get to choose **before our model is fit to the data**.\n",
    "    - Think of hyperparameters as knobs ğŸ› â€“ **we get to pick and tune them!**\n",
    "    - **Polynomial degree** was a hyperparameter in the previous example, and we tried three different values: 1, 3, and 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1dfbc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How do we choose the \"right\" hyperparameter(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f97b99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2e40f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We know that a model's performance on a **test set** is a good estimate of its ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bc6c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to find the hyperparameter that leads to the best **test set performance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e28be9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Idea:\n",
    "    1. Come up with a **list** of hyperparameters to try.\n",
    "    2. For each hyperparameter, train the model on the training set and compute its performance on the test set.\n",
    "    3. Pick the hyperparameter with the best performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31001a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error\n",
    "\n",
    "- Let's try this strategy on Sample 1 from our earlier example. \n",
    "\n",
    "- We'll try to fit a polynomial model on the dataset; we'll choose the polynomial's degree from the list [1, 2, ..., 25]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c1eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we perform a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_1[['x']]\n",
    "y = sample_1['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802b8d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ğŸ’¡ Pro-Tip: Using `make_pipeline`\n",
    "\n",
    "Instead of using the `Pipeline` class directly, you can use `make_pipeline` for a more compact syntax:\n",
    "\n",
    "(Also, there's an analogous `sklearn.compose.make_column_transformer` for the `ColumnTransformer` class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with degree-2 polynomial features\n",
    "pl = Pipeline([('poly', PolynomialFeatures(2)), ('lin-reg', LinearRegression())])\n",
    "\n",
    "# Same pipeline, notice that make_pipeline generates names for pipeline steps\n",
    "pl = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ff996",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial degree vs. train/test error\n",
    "\n",
    "Now, we'll create models with degree-1 through degree-25 polynomial features and compute their train and test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "for d in range(1, 26):\n",
    "    pl = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    pl.fit(X_train, y_train)\n",
    "    train_errs.append(mean_squared_error(y_train, pl.predict(X_train), squared=False))\n",
    "    test_errs.append(mean_squared_error(y_test, pl.predict(X_test), squared=False))\n",
    "\n",
    "errs = pd.DataFrame({'Train Error': train_errs, 'Test Error': test_errs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06ac65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the plots of training error vs. degree and test error vs. degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(errs)\n",
    "fig.update_layout(showlegend=True, xaxis_title='Polynomial Degree', yaxis_title='RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dfbf6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Training error appears to decrease as polynomial degree increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724335d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Test error appears to decrease until a \"valley\", and then increases again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e0bee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, we'd choose a degree of 3, since that degree has the **lowest test error**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abe896",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training error vs. test error\n",
    "\n",
    "The pattern we saw in the previous example is true more generally.\n",
    "\n",
    "<center><img src='imgs/tt-errors.png' width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728db66",
   "metadata": {},
   "source": [
    "We pick the hyperparameter(s) at the \"valley\" of test error.\n",
    "\n",
    "Note that training error **tends** to underestimate test error, but it doesn't have to â€“ i.e., it is possible for test error to be lower than training error (say, if the test set is \"easier\" to predict than the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bc281",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conducting train-test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88811055",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recall, <span style='color: blue'><b>training data</b></span> is used to fit our model, and <span style='color: orange'><b>test data</b></span> is used to evaluate our model.\n",
    "\n",
    "<center><img src='imgs/train-test-first.png' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6b2ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: _How_ should we split?\n",
    "    - `sklearn`'s `train_test_split` splits **randomly**, which usually works well.\n",
    "    - However, if there is some element of **time** in the training data (say, when predicting the future price of a stock), a better split is \"past\" and \"future\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1df4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: How _large_ should the split be, e.g. 90%-10% vs. 75%-25%?\n",
    "    - There's a tradeoff â€“ a larger training set should lead to a \"better\" model, while a larger test set should lead to a better estimate of our model's ability to generalize.\n",
    "    - There's no \"right\" choice, but we usually choose between 10% to 25% for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf0394",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But wait..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c19ac8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- With our current strategy, we are choosing the hyperparameter that creates the model that **performs best on the test set**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427cc42",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we are **overfitting to the test set** â€“ the best hyperparameter for the test set might not be the best hyperparameter for a totally unseen dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01584eef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It seems like we need **another** split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36a7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c7b052",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea: A single validation set\n",
    "\n",
    "<center><img src='imgs/train-test-val.png' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344ac51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Split the data into three sets: <span style='color: blue'><b>training</b></span>, <span style='color: green'><b>validation</b></span>, and <span style='color: orange'><b>test</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d7d91",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. For each hyperparameter choice, <span style='color: blue'><b>train</b></span> the model only on the <span style='color: blue'><b>training set</b></span>, and <span style='color: green'><b>evaluate</b></span> the model's performance on the <span style='color: green'><b>validation set</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b66367d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Find the hyperparameter with the best <span style='color: green'><b>validation</b></span> performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad93210",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Retrain the final model on the <span style='color: blue'><b>training</b></span> and <span style='color: green'><b>validation</b></span> sets, and report its performance on the <span style='color: orange'><b>test set</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e49e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue**: This strategy is too dependent on the <span style='color: green'><b>validation</b></span> set, which may be small and/or not a representative sample of the data. **We're not going to do this.** âŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9131a04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A better idea: $k$-fold cross-validation\n",
    "\n",
    "Instead of relying on a single <span style='color: green'><b>validation</b></span> set, we can create $k$ <span style='color: green'><b>validation</b></span> sets, where $k$ is some positive integer (5 in the example below).\n",
    "\n",
    "<center><img src='imgs/k-fold.png' width=40%></center>\n",
    "\n",
    "Since each data point is used for <span style='color: blue'><b>training</b></span> $k-1$ times and <span style='color: green'><b>validation</b></span> once, the (averaged) <span style='color: green'><b>validation</b></span> performance should be a good metric of a model's ability to generalize to unseen data.\n",
    "\n",
    "$k$-fold cross-validation (or simply \"cross-validation\") is **the** technique we will use for finding hyperparameters, or more generally, for choosing between different possible models. **It's what you should use in Project 4!** âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4b3f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating folds in `sklearn`\n",
    "\n",
    "`sklearn` has a `KFold` class that splits data into training and validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b67ce",
   "metadata": {},
   "source": [
    "Let's use a simple dataset for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(10, 70, 10)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43ac2a",
   "metadata": {},
   "source": [
    "Let's instantiate a `KFold` object with $k=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(3, shuffle=True, random_state=1)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf8557",
   "metadata": {},
   "source": [
    "Finally, let's use `kfold` to `split` `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79701be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, val in kfold.split(data):\n",
    "    print(f'train: {data[train]}, validation: {data[val]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367e39b",
   "metadata": {},
   "source": [
    "Note that each value in `data` is used for validation exactly once and for training exactly twice. Also note that because we set `shuffle=True` the folds are not simply `[10, 20]`, `[30, 40]`, and `[50, 60]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de2c3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-fold cross-validation\n",
    "\n",
    "First, **shuffle** the entire training set randomly and **split** it into $k$ disjoint folds, or \"slices\". Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b39156",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For each hyperparameter:\n",
    "    - For each slice:\n",
    "        - Let the slice be the \"validation set\", $V$.\n",
    "        - Let the rest of the data be the \"training set\", $T$.\n",
    "        - Train a model using the selected hyperparameter on the training set $T$.\n",
    "        - Evaluate the model on the validation set $V$.\n",
    "    - Compute the **average** validation score (e.g. RMSE) for the particular hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb6540",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Choose the hyperparameter with the best average validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620c78d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-fold cross-validation in `sklearn`\n",
    "\n",
    "While you could manually use `KFold` to perform cross-validation, the `cross_val_score` function in `sklearn` implements $k$-fold cross-validation for us! \n",
    "\n",
    "```py\n",
    "cross_val_score(estimator, X_train, y_train, cv)\n",
    "```\n",
    "\n",
    "Specifically, it takes in:\n",
    "- A `Pipeline` or estimator **that has not already been `fit`**.\n",
    "- Training data.\n",
    "- A value of $k$ (through the `cv` argument).\n",
    "- (Optionally) A `scoring` metric.\n",
    "\n",
    "and performs $k$-fold cross-validation, returning the values of the scoring metric on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1244ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ca832",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-fold cross-validation in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eaa524",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's perform $k$-fold cross validation in order to help us pick a degree for polynomial regression from the list [1, 2, ..., 25]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6df303",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll use $k=5$ since it's a common choice (and the default in `sklearn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c570d08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For the sake of this example, we'll suppose `sample_1` is our \"training + validation data\", i.e. that our test data is in some other dataset.\n",
    "    - If this were not true, we'd first need to split `sample_1` into separate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e26f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df = pd.DataFrame()\n",
    "\n",
    "for d in range(1, 26):\n",
    "    pl = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    \n",
    "    # The `scoring` argument is used to specify that we want to compute the RMSE; \n",
    "    # the default is R^2. It's called \"neg\" RMSE because, \n",
    "    # by default, sklearn likes to \"maximize\" scores, and maximizing -RMSE is the same\n",
    "    # as minimizing RMSE.\n",
    "    errs = cross_val_score(pl, sample_1[['x']], sample_1['y'], \n",
    "                           cv=5, scoring='neg_root_mean_squared_error')\n",
    "    errs_df[f'Deg {d}'] = -errs # Negate to turn positive (sklearn computed negative RMSE).\n",
    "    \n",
    "errs_df.index = [f'Fold {i}' for i in range(1, 6)]\n",
    "errs_df.index.name = 'Validation Fold'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c7311d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next class, we'll look at how to implement this procedure without needing to `for`-loop over values of `d`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ed7f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-fold cross-validation in `sklearn`\n",
    "\n",
    "Note that for each choice of degree (our hyperparameter), we have **five** RMSEs, one for each \"fold\" of the data. This means that in total, $5 \\cdot 25 = 125$ models were trained/fit to data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ba737",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914d676",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We should choose the degree with the lowest **average** validation RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df.mean().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aeacff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that if we didn't perform $k$-fold cross-validation, but instead just used a single validation set, we may have ended up with a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de811f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df.idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc6717",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "***Note***: You may notice that the RMSEs in Folds 1 and 5 are much higher than in other folds. Can you think of reasons why, and how we might fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f912b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8239bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another example: Tips\n",
    "\n",
    "We can also use $k$-fold cross-validation to determine which subset of features to use in a linear model that predicts tips by making one pipeline for each subset of features we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_column_transformer is a shortcut for the ColumnTransformer class\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f774ac",
   "metadata": {},
   "source": [
    "As we should always do, we'll perform a train-test split on `tips` and will only use the training data for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips.drop('tip', axis=1)\n",
    "y = tips['tip']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2853dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary that maps names to Pipeline objects.\n",
    "pipes = {\n",
    "    'total_bill only': make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(lambda x: x), ['total_bill']),\n",
    "        ),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'total_bill + size': make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(lambda x: x), ['total_bill', 'size']),\n",
    "        ),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'total_bill + size + OHE smoker': make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(lambda x: x), ['total_bill', 'size']),\n",
    "            (OneHotEncoder(drop='first'), ['smoker']),\n",
    "        ),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'total_bill + size + OHE all': make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(lambda x: x), ['total_bill', 'size']),\n",
    "            (OneHotEncoder(drop='first'), ['smoker', 'sex', 'time', 'day']),\n",
    "        ),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b42ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df = pd.DataFrame()\n",
    "\n",
    "for pipe in pipes:\n",
    "    errs = cross_val_score(pipes[pipe], X_train, y_train,\n",
    "                           cv=5, scoring='neg_root_mean_squared_error')\n",
    "    pipe_df[pipe] = -errs\n",
    "    \n",
    "pipe_df.index = [f'Fold {i}' for i in range(1, 6)]\n",
    "pipe_df.index.name = 'Validation Fold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09420210",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df.mean().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9ae70",
   "metadata": {},
   "source": [
    "Even though the third model has the lowest average validation RMSE, its average validation RMSE is very close to that of the other, simpler models, and as a result we'd likely use the simplest model in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf1012",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "<h3>Exercise</h3>\n",
    "    \n",
    "- Suppose you have a training dataset with 1000 rows.\n",
    "- You want to decide between 20 hyperparameters for a particular model.\n",
    "- To do so, you perform 10-fold cross-validation.\n",
    "- **How many times is the first row in the training dataset (`X.iloc[0]`) used for training a model?**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b3ad4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e9ba8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Split the data into two sets: <span style='color: blue'><b>training</b></span> and <span style='color: orange'><b>test</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b7200",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Use only the <span style='color: blue'><b>training</b></span> data when designing, training, and tuning the model.\n",
    "    - Use <span style='color: green'><b>$k$-fold cross-validation</b></span> to choose hyperparameters and estimate the model's ability to generalize.\n",
    "    - Do not âŒ look at the <span style='color: orange'><b>test</b></span> data in this step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e6340",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Commit to your final model and train it using the entire <span style='color: blue'><b>training</b></span> set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9dd3db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Test the data using the <span style='color: orange'><b>test</b></span> data. If the performance (e.g. RMSE) is not acceptable, return to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3dc5a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Finally, train on **all available data** and ship the model to production! ğŸ›³"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662df112",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ğŸš¨ This is the process you should **always** use! ğŸš¨ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44bead",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ğŸ¤” (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72e409",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision trees ğŸŒ²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6646d38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/ml-taxonomy.svg' width=50%></center>\n",
    "\n",
    "Decision trees can be used for both regression and classification. We'll start by using them for **classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f1289",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Should I get groceries?\n",
    "\n",
    "Decision trees make classifications by answering a series of yes/no questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8a413",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='imgs/dtree-basic.svg' width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8269fb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Internal **nodes** of trees involve questions; leaf nodes make predictions $H(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8070e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='imgs/dtree-basic-plot.svg' width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569dd49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83270fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(Path('data') / 'diabetes.csv')\n",
    "display_df(diabetes, cols=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c4fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0 means no diabetes, 1 means yes diabetes.\n",
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d4eb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'Glucose'` is measured in mg/dL (milligrams per deciliter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ea02c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'BMI'` is calculated as $\\text{BMI} = \\frac{\\text{weight (kg)}}{\\left[ \\text{height (m)} \\right]^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82906445",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's use `'Glucose'` and `'BMI'` to predict whether or not a patient has diabetes (`'Outcome'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d2b73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring the dataset\n",
    "\n",
    "First, a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c699036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(diabetes[['Glucose', 'BMI']], diabetes['Outcome'], random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb537748",
   "metadata": {},
   "source": [
    "<span style='color: orange'><b>Class 0 (orange) is \"no diabetes\"</b></span> and <span style='color: blue'><b>class 1 (blue) is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4445bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = (\n",
    "    X_train.assign(Outcome=y_train.astype(str))\n",
    "            .plot(kind='scatter', x='Glucose', y='BMI', color='Outcome', \n",
    "                  color_discrete_map={'0': 'orange', '1': 'blue'},\n",
    "                  title='Relationship between Glucose, BMI, and Diabetes')\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f94087",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a decision tree\n",
    "\n",
    "Let's build a decision tree and interpret the results.\n",
    "\n",
    "The relevant class is `DecisionTreeClassifier`, from `sklearn.tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12902788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b06503",
   "metadata": {},
   "source": [
    "Note that we `fit` it the same way we `fit` earlier estimators.\n",
    "\n",
    "_You may wonder what `max_depth` and `criterion` do â€“ more on this soon!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5efa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4fc97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing decision trees\n",
    "\n",
    "Our fit decision tree is like a \"flowchart\", made up of a series of questions.\n",
    "\n",
    "As before, <span style='color: orange'><b>orange is \"no diabetes\"</b></span> and <span style='color: blue'><b>blue  is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plot_tree(dt, feature_names=X_train.columns, class_names=['no db', 'yes db'], \n",
    "          filled=True, fontsize=15, impurity=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f6931",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To **classify a new data point**, we start at the top and answer the first question (i.e. \"Glucose <= 129.5\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c96291",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the answer is \"**Yes**\", we move to the **left** branch, otherwise we move to the right branch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1432dfa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We repeat this process until we end up at a leaf node, at which point we predict the most common class in that node.\n",
    "    - Note that each node has a `value` attribute, which describes the number of **training** individuals of each class that fell in that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the left node at depth 2 has a `value` of [304, 78].\n",
    "y_train[X_train.query('Glucose <= 129.5').index].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73e4cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating classifiers\n",
    "\n",
    "The most common evaluation metric in classification is **accuracy**:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{# data points classified correctly}}{\\text{# data points}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dt.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d61d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `score` method of a classifier computes accuracy by default (just like the `score` method of a regressor computes $R^2$ by default). We want our classifiers to have **high accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bde429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy â€“ same number as above\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4045e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83213dcc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e36ccd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Decision trees are easily interpretable: it is clear _how_ they make their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48d00b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- They work with categorical data without needing to use one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c046af0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- They also can be used in multi-class classification problems, e.g. when there are more than 2 possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e7c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The _decision boundary_ of a decision tree can be arbitrarily complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb19142",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **How are decision trees trained?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda55de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How are decision trees trained?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "```python\n",
    "def make_tree(X, y):\n",
    "    if all points in y have the same label C:\n",
    "        return Leaf(C)\n",
    "    f = best splitting feature # e.g. Glucose or BMI\n",
    "    v = best splitting value   # e.g. 129.5\n",
    "    \n",
    "    X_left, y_left   = X, y where (X[f] <= v)\n",
    "    X_right, y_right = X, y where (X[f] > v)\n",
    "    \n",
    "    left  = make_tree(X_left, y_left)\n",
    "    right = make_tree(X_right, y_right)\n",
    "    \n",
    "    return Node(f, v, left, right)\n",
    "    \n",
    "make_tree(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a105e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we measure the quality of a split?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214872f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our pseudocode for training a decision tree relies on finding the best way to \"split\" a node â€“ that is, **the best question to ask** to help us narrow down which class to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621a012",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Intuition**: Suppose the distribution within a node looks like this (colors represent classes):\n",
    "\n",
    "<center>ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ</center>\n",
    "\n",
    "Split A:\n",
    "- \"Yes\": ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µ\n",
    "- \"No\": ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µ\n",
    "\n",
    "Split B:\n",
    "- \"Yes\": ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ\n",
    "- \"No\": ğŸ”µğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ \n",
    "\n",
    "**Which split is \"better\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701e7e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Split B, because there is \"less uncertainty\" in the resulting nodes in Split B than there is in Split A. Let's try and quantify this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af8be0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46462eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For each class $C$ within a node, define $p_C$ as the proportion of points with that class.\n",
    "    - For example, the two classes may be \"yes diabetes\" and \"no diabetes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1414f15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **surprise** of drawing a point from the node at random and having it be class $C$ is:\n",
    "\n",
    "$$\n",
    "- \\log_2 p_C\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7095a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **entropy** of a node is the average surprise over all classes:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{entropy} &= - \\sum_C p_C \\log_2 p_C\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d04fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The entropy of ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ  is $ -1 \\log_2(1) = 0 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dc897",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The entropy of ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µ is $ -0.5 \\log_2(0.5) - 0.5 \\log_2(0.5) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98afe088",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The entropy of ğŸŸ ğŸ”µğŸŸ¢ğŸŸ¡ğŸŸ£ is $ - \\log_2 \\frac{1}{5} = \\log_2(5) $\n",
    "    - In general, if a node has $n$ points, all with different labels, the entropy of the node is $ \\log_2(n) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28fe85d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example entropy calculation\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "<center>ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ</center>\n",
    "\n",
    "Split A:\n",
    "- \"Yes\": ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µ\n",
    "- \"No\": ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ\n",
    "\n",
    "Split B:\n",
    "- \"Yes\": ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µ\n",
    "- \"No\": ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdc7b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We choose the split that has the lowest **weighted entropy**, that is:\n",
    "\n",
    "$$\\text{entropy of split} = \\frac{\\# \\text{Yes}}{\\# \\text{Yes} + \\# \\text{No}} \\cdot \\text{entropy(Yes)} + \\frac{\\# \\text{No}}{\\# \\text{Yes} + \\# \\text{No}} \\cdot \\text{entropy(No)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e63931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(node):\n",
    "    props = pd.Series(list(node)).value_counts(normalize=True)\n",
    "    return -sum(props * np.log2(props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a38b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_entropy(yes_node, no_node):\n",
    "    yes_entropy = entropy(yes_node)\n",
    "    no_entropy = entropy(no_node)\n",
    "    yes_weight = len(yes_node) / (len(yes_node) + len(no_node))\n",
    "    return yes_weight * yes_entropy + (1 - yes_weight) * no_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e62521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split A:\n",
    "weighted_entropy(\"ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µ\", \"ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split B:\n",
    "weighted_entropy(\"ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µ\", \"ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸŸ ğŸ”µğŸ”µğŸ”µ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d910d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Split A has the lower weighted entropy, so we'll use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61477abd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Understanding entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plot_tree(dt, feature_names=X_train.columns, class_names=['no db', 'yes db'], \n",
    "          filled=True, fontsize=15, impurity=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf312fe",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "We can recreate the entropy calculations above! Note that the default `DecisionTreeClassifier` uncertaintly metric _isn't_ entropy; it used entropy because we set `criterion='entropy'` when defining `dt`. (The default metric, [Gini impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#:~:text=Gini%20impurity%20measures%20how%20often,into%20a%20single%20target%20category.), is perfectly fine too!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first node at depth 2 has an entropy of 0.73,\n",
    "# both told to us above and verified here!\n",
    "entropy([0] * 304 + [1] * 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa9328",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ğŸ¤” (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63715f3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree depth\n",
    "\n",
    "Decision trees are trained by **recursively** picking the best split until:\n",
    "\n",
    "- all \"leaf nodes\" only contain training examples from a single class (good), or\n",
    "- it is impossible to split leaf nodes any further (not good).\n",
    "\n",
    "By default, there is no \"maximum depth\" for a decision tree. As such, without restriction, decision trees tend to be very deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max = DecisionTreeClassifier()\n",
    "dt_no_max.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7ab31",
   "metadata": {},
   "source": [
    "A decision tree fit on our training data has a depth of around 20! (It is so deep that `tree.plot_tree` errors when trying to plot it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c06bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30caeb75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At first, this tree seems \"better\" than our tree of depth 2, since its training accuracy is much much higher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 2 tree.\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf99510",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But recall, we truly care about **test set performance**, and this decision tree has **worse accuracy on the test set than our depth 2 tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f35a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 2 tree.\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1e183",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769f0d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Decision trees have a tendency to overfit. **Why is that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466852f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unlike linear classification techniques (like logistic regression or SVMs), **decision trees are non-linear**.\n",
    "    - They are also \"non-parametric\" â€“ there are no $w^*$s to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76fd16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- While being trained, decision trees ask enough questions to effectively **memorize** the correct response values in the training set. However, the relationships they learn are often overfit to the noise in the training set, and don't generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e165b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f563e29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A decision tree whose depth is not restricted will achieve 100% accuracy on any training set, as long as there are no \"overlapping values\" in the training set.\n",
    "    - Two values overlap when they have the same features $x$ but different response values $y$ (e.g. if two patients have the same glucose levels and BMI, but one has diabetes and one doesn't)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564b552",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One solution**: Make the decision tree \"less complex\" by limiting the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87429ef6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since `sklearn.tree`'s `plot_tree` can't visualize extremely large decision trees, let's create and visualize some smaller decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66549935",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = {}\n",
    "for d in [2, 4, 8]:\n",
    "    trees[d] = DecisionTreeClassifier(max_depth=d, random_state=1)\n",
    "    trees[d].fit(X_train, y_train)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5), dpi=100)\n",
    "    plot_tree(trees[d], feature_names=X_train.columns, class_names=['no db', 'yes db'], \n",
    "               filled=True, rounded=True, impurity=False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c504a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As tree depth increases, complexity increases, and our trees are more prone to overfitting. This means model bias decreases, but model variance increases. \n",
    "\n",
    "**Question**: What is the \"right\" maximum depth to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ba76e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparameters for decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6fcb22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `max_depth` is a hyperparameter for `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81005e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are many more hyperparameters we can tweak; look at [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for examples.\n",
    "    - `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "    - `criterion`: The function to measure the quality of a split (`'gini'` or `'entropy'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2dc4ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To ensure that our model generalizes well to unseen data, we need an efficient technique for trying different combinations of hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da682d20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll see that technique next time: `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191f3ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08521e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- A hyperparameter is a configuration that we choose before training a model; an important task in machine learning is selecting \"good\" hyperparameters.\n",
    "- To choose hyperparameters, we use $k$-fold cross-validation. **This technique is very common, and you are expected to use it in Project 4!**\n",
    "    - See [Summary: Generalization](#Summary:-Generalization) for more.\n",
    "- Decision trees can be used for both regression and classification; we've used them for classification.\n",
    "    - Decision trees are trained recursively. Each node corresponds to a \"yes\" or \"no\" question.\n",
    "    - To decide which \"yes\" or \"no\" question to ask, we choose the question with the lowest weighted entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62eb104",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- An efficient technique for trying different combinations of hyperparameters.\n",
    "    - In other words, performing $k$-fold cross-validation _without_ a `for`-loop.\n",
    "- Techniques for evaluating classifiers beyond accuracy.\n",
    "    - You'll need this for Project 4!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
