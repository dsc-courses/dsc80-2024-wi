{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 10 ‚Äì Web Scraping\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Project 2 is due **today**.\n",
    "    - You can use up to 3 slip days on it, and everyone now has 7 slip days.\n",
    "- Lab 6 will be released soon, and will be due on **Wednesday, February 21st at 5PM** (no slip days!).\n",
    "    - Remember that next Monday is a holiday.\n",
    "- Project 3 will be released later this week.\n",
    "- **If at least 80% of the class fills out the [Mid-Quarter Survey](https://docs.google.com/forms/d/e/1FAIpQLScHz9WJMST7QLKCl2cR3Oc3r-DO7qn4rutM_dCN8R7gluy5MA/viewform) by Saturday at 11:59PM, everyone will learn 2 extra points on the Midterm Exam!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ \n",
    "\n",
    "- Review: Accessing HTML.\n",
    "- HTML basics.\n",
    "- Parsing HTML using BeautifulSoup.\n",
    "- Example: Scraping quotes.\n",
    "- Example: Scraping the HDSI faculty page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8517ebf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "\n",
    "How many slip days do you plan on using on Project 2?\n",
    "    \n",
    "- 0: I already submitted it!\n",
    "- 0: I plan on submitting it today.\n",
    "- 1.\n",
    "- 2.\n",
    "- 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc524c7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Accessing HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d068f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making requests\n",
    "\n",
    "**Goal**: Access information about HDSI faculty members from the HDSI Faculty page.\n",
    "\n",
    "Let's start by making a GET request to the HDSI Faculty page and see what the resulting HTML looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ea7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1eb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_response = requests.get('https://datascience.ucsd.edu/faculty/')\n",
    "fac_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80dbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_text = fac_response.text\n",
    "len(fac_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fac_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efd3a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wow, that is gross looking! üò∞ \n",
    "\n",
    "- It is **raw** HTML, which web browsers use to display websites.\n",
    "- The information we are looking for ‚Äì faculty information ‚Äì is in there somewhere, but we have to search for it and extract it, which we wouldn't have to do if we had an API.\n",
    "- We'll now look at how HTML documents are structured and how to extract information from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a992c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Best practices for scraping\n",
    "\n",
    "1. **Send requests slowly** and be upfront about what you are doing!\n",
    "2. Respect the policy published in the page's `robots.txt` file.\n",
    "    - Many sites have a `robots.txt` file in their root directory, which contains a policy that allows or disallows automatic access to their site. \n",
    "    - If there isn't one, like in Project 3, use a 0.5 second delay between requests.\n",
    "3. Don't spoof your User-agent (i.e. don't try to trick the server into thinking you are a person).\n",
    "4. Read the Terms of Service for the site and follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20aea1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consequences of irresponsible scraping\n",
    "\n",
    "If you make too many requests:\n",
    "* The server may block your IP Address.\n",
    "* You may take down the website.\n",
    "    - A journalist scraped and accidentally took down the Cook County Inmate Locater.\n",
    "    - As a result, inmate's families weren't able to contact them while the site was down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d59993",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: APIs vs. scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8bbfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **APIs** are made by organizations that host data.\n",
    "    - For example, X (formally known as Twitter) has an [API](https://developer.twitter.com/en/docs/twitter-api).\n",
    "    - APIs provide a code-friendly way to access data.\n",
    "    - Usually, APIs give us back data as JSON objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6a888",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Scraping** is the act of emulating a web browser to access its source code.\n",
    "    - As you saw in Lab 5, it's not technically supported by most organizations.\n",
    "    - When scraping, you get back data as HTML and have to parse that HTML to extract the information you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed586479",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The anatomy of HTML documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc2b88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is HTML?\n",
    "\n",
    "* HTML (HyperText Markup Language) is **the** basic building block of the internet. \n",
    "* It defines the content and layout of a webpage, and as such, it is what you get back when you scrape a webpage.\n",
    "* See [this tutorial](https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0d895",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For instance, here's the content of a very basic webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec10_ex1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0b186",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using `IPython.display.HTML`, we can render it directly in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c4f5b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename=Path('data') / 'lec10_ex1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab3db3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The anatomy of HTML documents\n",
    "\n",
    "* **HTML document**: The totality of markup that makes up a webpage.\n",
    "\n",
    "* **Document Object Model (DOM)**: The internal representation of an HTML document as a hierarchical **tree** structure.\n",
    "\n",
    "* **HTML element**: An object in the DOM, such as a paragraph, header, or title.\n",
    "* **HTML tags**: Markers that denote the **start** and **end** of an element, such as `<p>` and `</p>`.\n",
    "\n",
    "<center><img src='imgs/dom.jpg'></center>\n",
    "\n",
    "<center><a href='https://simplesnippets.tech/what-is-document-object-modeldom-how-js-interacts-with-dom/'>(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13404bf2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful tags to know\n",
    "\n",
    "\n",
    "|Element|Description|\n",
    "|:---|:---|\n",
    "|`<html>`|the document|\n",
    "|`<head>`|the header|\n",
    "|`<body>`|the body|\n",
    "|`<div>` |a logical division of the document|\n",
    "|`<span>`|an *inline* logical division|\n",
    "|`<p>`|a paragraph|\n",
    "| `<a>`| an anchor (hyperlink)|\n",
    "|`<h1>, <h2>, ...`| header(s) |\n",
    "|`<img>`| an image |\n",
    "\n",
    "There are many, many more. See [this article](https://en.wikipedia.org/wiki/HTML_element) for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3532d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Images and hyperlinks\n",
    "\n",
    "Tags can have **attributes**, which further specify how to display information on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5e6e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, `<img>` tags have `src` and `alt` attributes (among others):\n",
    "\n",
    "```html\n",
    "<img src=\"king-selfie.png\" alt=\"A photograph of King Triton.\" width=500>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96983121",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hyperlinks have `href` attributes: \n",
    "\n",
    "```html\n",
    "Click <a href=\"https://practice.dsc80.com\">this link</a> to access past exams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655cf7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do you think this webpage looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec10_ex2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbb9e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `<div>` tag\n",
    "\n",
    "```html\n",
    "<div style=\"background-color:lightblue\">\n",
    "  <h3>This is a heading</h3>\n",
    "  <p>This is a paragraph.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "* The `<div>` tag defines a division or a \"section\" of an HTML document.\n",
    "    * Think of a `<div>` as a \"cell\" in a Jupyter Notebook.\n",
    "\n",
    "* The `<div>` element is often used as a container for other HTML elements to style them with CSS or to perform operations involving them using JavaScript.\n",
    "\n",
    "* `<div>` elements often have attributes, **which are important when scraping**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6f3ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Document trees\n",
    "\n",
    "Under the document object model (DOM), HTML documents are trees. In DOM trees, child nodes are **ordered**.\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"imgs/webpage_anatomy.png\" width=\"50%\">\n",
    "\n",
    "</center>    \n",
    "\n",
    "What does the DOM tree look like for this document?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39915947",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/dom_tree.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a797498",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parsing HTML using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74bd7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beautiful Soup üçú\n",
    "\n",
    "* [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python HTML parser.\n",
    "    - To \"parse\" means to \"extract meaning from a sequence of symbols\".\n",
    "* **Warning**: Beautiful Soup 4 and Beautiful Soup 3 work differently, so make sure you are using and looking at documentation for Beautiful Soup 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b42bbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example HTML document\n",
    "\n",
    "To start, we'll work with the source code for an HTML page with the DOM tree shown below:\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"50%\"></center>\n",
    "\n",
    "The string `html_string` contains an HTML \"document\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0809c0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "    <body>\n",
    "      <div id=\"content\">\n",
    "        <h1>Heading here</h1>\n",
    "        <p>My First paragraph</p>\n",
    "        <p>My <em>second</em> paragraph</p>\n",
    "        <hr>\n",
    "      </div>\n",
    "      <div id=\"nav\">\n",
    "        <ul>\n",
    "          <li>item 1</li>\n",
    "          <li>item 2</li>\n",
    "          <li>item 3</li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3699a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7a4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `BeautifulSoup` objects\n",
    "\n",
    "`bs4.BeautifulSoup` takes in a string or file-like object representing HTML (`markup`) and returns a **parsed** document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4.BeautifulSoup?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352a2bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normally, we pass the result of a GET request to `bs4.BeautifulSoup`, but here we will pass our hand-crafted `html_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb904c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(html_string)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb1154",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`BeautifulSoup` objects have several useful attributes, e.g. `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78233a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traversing through `descendants`\n",
    "\n",
    "The `descendants` attribute traverses a `BeautifulSoup` tree using **depth-first traversal**.\n",
    "\n",
    "Why depth-first? Elements closer to one another on a page are more likely to be related than elements further away.\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867dc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in soup.descendants:\n",
    "#     print(child) # What would happen if we ran this instead?\n",
    "    if isinstance(child, str):\n",
    "        continue\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a21d52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding elements in a tree\n",
    "\n",
    "Practically speaking, you will not use the `descendants` attribute (or the related `children` attribute) directly very often. Instead, you will use the following methods:\n",
    "\n",
    "- `soup.find(tag)`, which finds the **first** instance of a tag (the first one on the page, i.e. the first one that DFS sees).\n",
    "    - More general: `soup.find(name=None, attrs={}, recursive=True, text=None, **kwargs)`.\n",
    "- `soup.find_all(tag)` will find **all** instances of a tag.\n",
    "\n",
    "**`find` finds tags!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468475e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find`\n",
    "\n",
    "Let's try and extract the first `<div>` subtree.\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d60ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9ec73",
   "metadata": {},
   "source": [
    "<center><img src=\"imgs/dom_subtree_1.png\" width=\"30%\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d7cfc",
   "metadata": {},
   "source": [
    "Let's try and find the `<div>` element that has an `id` attribute equal to `'nav'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', attrs={'id': 'nav'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc1aef",
   "metadata": {},
   "source": [
    "`find` will return the first occurrence of a tag, regardless of its depth in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6359708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ul child is not at the top of the tree, but we can still find it.\n",
    "soup.find('ul')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce4de4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find_all`\n",
    "\n",
    "`find_all` returns a list of all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e94fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Node attributes\n",
    "* The `text` attribute of a tag element gets the text between the opening and closing tags.\n",
    "* The `attrs` attribute of a tag element lists all of its attributes.\n",
    "* The `get` method of a tag element **gets the value of an attribute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a308ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1919b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f874f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `get` method must be called directly on the node that contains the attribute you're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While there are multiple 'id' attributes, none of them are in the <html> tag at the top.\n",
    "soup.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4116d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3ab55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "    \n",
    "Consider the following HTML document, which represents a webpage containing the top few songs with the most streams on Spotify today in Canada.\n",
    "\n",
    "```html\n",
    "<head>\n",
    "    <title>3*Canada-2022-06-04</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Spotify Top 3 - Canada</h1>\n",
    "    <table>\n",
    "        <tr class='heading'>\n",
    "            <th>Rank</th>\n",
    "            <th>Artist(s)</th> \n",
    "            <th>Song</th>\n",
    "        </tr>\n",
    "        <tr class=1>\n",
    "            <td>1</td>\n",
    "            <td>Harry Styles</td> \n",
    "            <td>As It Was</td>\n",
    "        </tr>\n",
    "        <tr class=2>\n",
    "            <td>2</td>\n",
    "            <td>Jack Harlow</td> \n",
    "            <td>First Class</td>\n",
    "        </tr>\n",
    "        <tr class=3>\n",
    "            <td>3</td>\n",
    "            <td>Kendrick Lamar</td> \n",
    "            <td>N95</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a70b6e",
   "metadata": {},
   "source": [
    "**Part 1**: How many leaf nodes are there in the DOM tree of the previous document ‚Äî that is, how many nodes have no children?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f3382",
   "metadata": {},
   "source": [
    "**Part 2**: What does the following line of code evaluate to?\n",
    "\n",
    "```py\n",
    "len(soup.find_all(\"td\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5d79b",
   "metadata": {},
   "source": [
    "**Part 3**: What does the following line of code evaluate to?\n",
    "\n",
    "```py\n",
    "soup.find(\"tr\").get(\"class\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931a7c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635662b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Scraping quotes\n",
    "\n",
    "Consider [quotes.toscrape.com](https://quotes.toscrape.com).\n",
    "\n",
    "<center><img src=\"imgs/quotes2scrape.png\" width=60%></center>\n",
    "\n",
    "Goal: Extract quotes (and relevant metadata) into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb141b04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Specifically, let's try to make a DataFrame that looks like the one below:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>quote</th>\n",
    "      <th>author</th>\n",
    "      <th>author_url</th>\n",
    "      <th>tags</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>‚ÄúThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.‚Äù</td>\n",
    "      <td>Albert Einstein</td>\n",
    "      <td>https://quotes.toscrape.com/author/Albert-Einstein</td>\n",
    "      <td>change,deep-thoughts,thinking,world</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>‚ÄúIt is our choices, Harry, that show what we truly are, far more than our abilities.‚Äù</td>\n",
    "      <td>J.K. Rowling</td>\n",
    "      <td>https://quotes.toscrape.com/author/J-K-Rowling</td>\n",
    "      <td>abilities,choices</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>‚ÄúThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.‚Äù</td>\n",
    "      <td>Albert Einstein</td>\n",
    "      <td>https://quotes.toscrape.com/author/Albert-Einstein</td>\n",
    "      <td>inspirational,life,live,miracle,miracles</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e66358",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The plan\n",
    "\n",
    "Eventually, we will create a single function ‚Äì `make_quote_df` ‚Äì which takes in an integer `n` and returns a **DataFrame** with the quotes on the **first `n` pages** of [quotes.toscrape.com](https://quotes.toscrape.com).\n",
    "\n",
    "To do this, we will define several helper functions:\n",
    "\n",
    "- `download_page(i)`, which downloads a **single page** (page `i`) and returns a `BeautifulSoup` object of the response.\n",
    "\n",
    "- `process_quote(div)`, which takes in a `<div>` tree corresponding to a **single quote** and returns a dictionary containing all of the relevant information for that quote.\n",
    "\n",
    "- `process_page(divs)`, which takes in a list of `<div>` trees corresponding to a **single page** and returns a DataFrame containing all of the relevant information for all quotes on that page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66214488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key principle: some of our helper functions will make **requests**, and others will **parse**, but none will do both! \n",
    "- Easier to debug and catch errors.\n",
    "- Avoids unnecessary requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a4563",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Downloading a single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db125af",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def download_page(i):\n",
    "    url = f'https://quotes.toscrape.com/page/{i}'\n",
    "    request = requests.get(url)\n",
    "    return bs4.BeautifulSoup(request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452bb34",
   "metadata": {},
   "source": [
    "In `make_quote_df`, we will call `download_page` repeatedly ‚Äì once for `i=1`, once for `i=2`, ..., `i=n`. For now, we will work with just page 1 (chosen arbitrarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = download_page(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59697cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parsing a single page\n",
    "\n",
    "Let's look at the page's source code (right click the page and click \"Inspect\" in Chrome) to find where the quotes in the page are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152459",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', class_='quote')\n",
    "# Shortcut for the following, just for when the attribute key is class:\n",
    "# divs = soup.find_all('div', attrs={'class': 'quote'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6757bf4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From this `<div>`, we can extract the quote, author name, author's URL, and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The quote.\n",
    "divs[0].find('span', class_='text').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The author.\n",
    "divs[0].find('small', class_='author').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL for the author.\n",
    "divs[0].find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aafc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The quote's tags.\n",
    "divs[0].find('meta', class_='keywords').get('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497f2fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's implement our next function, `process_quote`, which takes in a `<div>` corresponding to a single quote and returns a dictionary containing the quote's information.\n",
    "\n",
    "Why use a dictionary? Passing `pd.DataFrame` a list of dictionaries is an easy way to create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_quote(div):\n",
    "    quote = div.find('span', class_='text').text\n",
    "    author = div.find('small', class_='author').text\n",
    "    author_url = 'https://quotes.toscrape.com' + div.find('a').get('href')\n",
    "    tags = div.find('meta', class_='keywords').get('content')\n",
    "    \n",
    "    return {'quote': quote, 'author': author, 'author_url': author_url, 'tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b620164",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_quote(divs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a761e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our last helper function will take in a **list** of `<div>`s, call `process_quote` on each `<div>` in the list, and return a **DataFrame**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(divs):\n",
    "    return pd.DataFrame([process_quote(div) for div in divs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3625b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_page(divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0408fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f71cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quote_df(n):\n",
    "    '''Returns a DataFrame containing the quotes on the first n pages of https://quotes.toscrape.com/.'''\n",
    "    dfs = []\n",
    "    for i in range(1, n+1):\n",
    "        # Download page n and create a BeautifulSoup object.\n",
    "        soup = download_page(i)\n",
    "        \n",
    "        # Create DataFrame using the information in that page.\n",
    "        divs = soup.find_all('div', class_='quote')\n",
    "        df = process_page(divs)\n",
    "        \n",
    "        # Append DataFrame to dfs.\n",
    "        dfs.append(df)\n",
    "        \n",
    "    # Stitch all DataFrames together.\n",
    "    return pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a410385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quotes = make_quote_df(3)\n",
    "quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes[quotes['author'] == 'Albert Einstein']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64de1c",
   "metadata": {},
   "source": [
    "The elements in the `'tags'` column are all strings, but they look like lists. This is not ideal, as we will see shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843566af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping the HDSI faculty page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369eb99b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Scraping the HDSI faculty page\n",
    "\n",
    "Let's try and extract a list of HDSI Faculty from [datascience.ucsd.edu/faculty](https://datascience.ucsd.edu/faculty).\n",
    "\n",
    "- As usual, we start by opening the page, right clicking somewhere on the page, and clicking \"Inspect\" in Chrome.\n",
    "- As we can see, the HTML is much more complicated ‚Äì this is usually the case for websites in the wild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3632dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_response = requests.get('https://datascience.ucsd.edu/faculty/')\n",
    "fac_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(fac_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d81b5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's not easy identifying which `<div>`s we want. The Inspect tool makes this easier, but it's good to verify that `find_all` is finding the right number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b2796",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "divs = soup.find_all(\n",
    "    class_='vc_grid-item',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ff002",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba3737",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Within here, we need to extract each faculty member's name. It seems like names are stored as text within the `<h4>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f561fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "divs[0].find('h4').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebbac3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also extract job titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb91b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find(class_='field').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95094856",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a DataFrame consisting of names and job titles for each faculty member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac3b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = [div.find('h4').text for div in divs]\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba7fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = [div.find(class_='field').text for div in divs]\n",
    "titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty = pd.DataFrame({\n",
    "    'name': names, \n",
    "    'title': titles, \n",
    "})\n",
    "faculty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce49fa",
   "metadata": {},
   "source": [
    "Now we have a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty[faculty['title'].str.contains('Teaching') | faculty['title'].str.contains('Lecturer')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247b351",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to get faculty members' pictures? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fadc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "def show_picture(name):\n",
    "    idx = faculty[faculty['name'].str.lower().str.contains(name.lower())].index[0]\n",
    "    display(Image(divs[idx].find('img')['src'], width=200, height=200))\n",
    "    \n",
    "show_picture('marina')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbd8ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "    <h3>Exercise</h3>\n",
    "    \n",
    "Consider the following HTML document, which represents a webpage containing the top few songs with the most streams on Spotify today in Canada.\n",
    "\n",
    "```html\n",
    "<head>\n",
    "    <title>3*Canada-2022-06-04</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Spotify Top 3 - Canada</h1>\n",
    "    <table>\n",
    "        <tr class='heading'>\n",
    "            <th>Rank</th>\n",
    "            <th>Artist(s)</th> \n",
    "            <th>Song</th>\n",
    "        </tr>\n",
    "        <tr class=1>\n",
    "            <td>1</td>\n",
    "            <td>Harry Styles</td> \n",
    "            <td>As It Was</td>\n",
    "        </tr>\n",
    "        <tr class=2>\n",
    "            <td>2</td>\n",
    "            <td>Jack Harlow</td> \n",
    "            <td>First Class</td>\n",
    "        </tr>\n",
    "        <tr class=3>\n",
    "            <td>3</td>\n",
    "            <td>Kendrick Lamar</td> \n",
    "            <td>N95</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "**Part 4**: Complete the implementation of the function `top_nth`, which takes in a positive integer `n` and returns the name of the n-th ranked song in the HTML document. For instance, `top_nth(2)` should evaluate to `\"First Class\"` (`n=1` corresponds to the top song).\n",
    "\n",
    "Note: Your implementation should work in the case that the page contains more than 3 songs.\n",
    "\n",
    "```py\n",
    "def top_nth(n):\n",
    "    return soup.find(\"tr\", attrs=__(a)__).find_all(\"td\")__(b)__\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad66d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Web data in practice\n",
    "\n",
    "[The spread of true and false news online](https://www.science.org/doi/full/10.1126/science.aap9559) by Vosoughi et al. compared how true and false news spreads via Twitter:\n",
    "\n",
    "> There is worldwide concern over false news and the possibility that it can influence political, economic, and social well-being. To understand how false news spreads, Vosoughi et al. used a data set of rumor cascades on Twitter from 2006 to 2017. About 126,000 rumors were spread by ‚àº3 million people. False news reached more people than the truth; the top 1% of false news cascades diffused to between 1000 and 100,000 people, whereas the truth rarely diffused to more than 1000 people. Falsehood also diffused faster than the truth. The degree of novelty and the emotional reactions of recipients may be responsible for the differences observed.\n",
    "\n",
    "To conduct this study, the authors used the Twitter API for accessing tweets and web-scraped fact-checking websites to verify whether news was false or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time\n",
    "\n",
    "- Beautiful Soup is an HTML parser that allows us to (somewhat) easily extract information from HTML documents.\n",
    "    - `soup.find` and `soup.find_all` are the functions you will use most often.\n",
    "- When writing scraping code:\n",
    "    - Use \"inspect element\" to identify the names of tags and attributes that are relevant to the information you want to extract.\n",
    "    - Separate your logic for making requests and for parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72e61d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Regular expressions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
