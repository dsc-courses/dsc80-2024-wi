{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2b2f7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly (and seaborn)!\n",
    "# We shuffle here so that the head of the DataFrame contains rows where smoker is Yes and smoker is No,\n",
    "# purely for illustration purposes (it doesn't change any of the math).\n",
    "np.random.seed(1)\n",
    "tips = px.data.tips().sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 14 ‚Äì Feature Engineering\n",
    "\n",
    "## DSC 80, Winter 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Project 3 is due **this Thursday, February 29th**.\n",
    "- Lab 8 is due on **Monday, March 4th**.\n",
    "- Project 4 will be released soon, and will be due on **Thursday, March 21st**.\n",
    "    - It will be worth two projects (because it used to be two separate projects). Think of it like an open-ended final project.\n",
    "    - It will have a very short checkpoint, due on **Thursday, March 7th**.\n",
    "    - You **cannot** use slip days on the final deadline.\n",
    "- The Final Exam is in three weeks from today, on **Tuesday, March 19th from 3-6PM**.\n",
    "    - Two more old exams now have detailed solutions on [practice.dsc80.com](https://practice.dsc80.com): the [Winter 2023 Final](https://practice.dsc80.com/wi23-final) and the [Fall 2023 Final](https://practice.dsc80.com/fa23-final).\n",
    "    - We're working on uploading more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97309cd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RSVP to the senior capstone showcase on March 15th!\n",
    "\n",
    "The senior capstone showcase is on Friday, March 15th in the **Price Center East Ballroom**. The DSC seniors will be presenting posters on their capstone projects. Come and ask them questions; if you're a DSC major, this will be you one day!\n",
    "\n",
    "<center><img src=\"imgs/Quarter 2 Project Poster.jpeg\" width=600><i>Last year's showcase.</i></center>\n",
    "\n",
    "The session is broken into two blocks:\n",
    "\n",
    "- Block 1: 11AM-12:30PM.\n",
    "- Block 2: 1-2:30PM.\n",
    "\n",
    "<center>\n",
    "<h3>Look at the list of topics and RSVP at <a href=\"https://hdsishowcase.com\">hdsishowcase.com</a>!\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Review: Predicting tips.\n",
    "    - $R^2$.\n",
    "- Feature engineering.\n",
    "    - Example: Predicting tips.\n",
    "        - One hot encoding.\n",
    "    - Example: Predicting ratings ‚≠êÔ∏è.\n",
    "        - Dropping features.\n",
    "        - Ordinal encoding.\n",
    "    - Example: Horsepower üöó.\n",
    "        - Quantitative scaling.\n",
    "- Feature engineering in `sklearn`.\n",
    "    - Transformer classes.\n",
    "    - Creating `Pipeline`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398eb093",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "Remember, you can always ask questions at [**q.dsc80.com**](https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review: Predicting tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cdc9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbdebf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear models\n",
    "\n",
    "Last time, we _fit_ three linear models to predict restaurant tips:\n",
    "\n",
    "- Constant model: $\\text{predicted tip} = h$.\n",
    "- Simple linear regression: $\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill}$.\n",
    "- Multiple linear regression: $\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648de16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the constant model case, we know that the optimal model parameter, when using squared loss, is $h^* = \\text{mean tip}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tip = tips['tip'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a60f9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the other two cases, we used the `LinearRegression` class from `sklearn` to help us find optimal model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])\n",
    "\n",
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912e89f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error\n",
    "\n",
    "To compare the performance of different models, we used the root mean squared error (RMSE).\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))\n",
    "\n",
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "\n",
    "all_preds = model.predict(tips[['total_bill']])\n",
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "\n",
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ae07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.score` method of a `LinearRegression` object\n",
    "\n",
    "Model objects in `sklearn` that have already been fit have a `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bd253",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That doesn't look like the RMSE... what is it? ü§î\n",
    "\n",
    "Last time, we left off on that cliffhanger üßó..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17aa8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77394e99",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $R^2$, or the **coefficient of determination**, is a measure of the **quality of a linear fit**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07cdd7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are a few equivalent ways of computing it, assuming your model **is linear and has an intercept term**:\n",
    "\n",
    "$$R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$$\n",
    "\n",
    "$$R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe95d1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Interpretation: $R^2$ is the **proportion of variance in $y$ that the linear model explains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fa9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the simple linear regression case, it is the square of the correlation coefficient, $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a320f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea:** $R^2$ ranges from 0 to 1. **The closer it is to 1, the better the linear fit is.**\n",
    "    - $R^2$ has no units of measurement, unlike RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10277e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "Let's calculate the $R^2$ for `model_two`'s predictions in three different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68507b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = tips.assign(predicted=model_two.predict(tips[['total_bill', 'size']]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57861383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(pred['predicted']) / np.var(pred['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a91f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$, the same correlation coefficient you saw in DSC 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.corr().loc['predicted', 'tip'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fe309",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 3:** `LinearRegression.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ffe7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f084",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a789",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relationship between $R^2$ and RMSE\n",
    "\n",
    "For linear models with an intercept term,\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\text{RMSE}^2}{\\text{var}(\\text{actual $y$ values})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - rmse(pred['tip'], pred['predicted']) ** 2 / np.var(pred['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153988b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, in our journey to predict `'tip'`, we've only used the existing numerical features in our dataset, `'total_bill'` and `'size'`.\n",
    "\n",
    "- There's a lot of information in tips that we didn't use ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'`, for example. We can't use these features in their current form, because they're non-numeric.\n",
    "\n",
    "- **How do we use categorical features in a regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b777e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7c091",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4a790",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A feature function $\\phi$ (phi, pronounced \"fea\") is a mapping from raw data to $d$-dimensional space, i.e. $\\phi: \\text{raw data} \\rightarrow \\mathbb{R}^d$.\n",
    "    - If two observations $x_i$ and $x_j$ are \"similar\" in the raw data space, then $\\phi(x_i)$ and $\\phi(x_j)$ should also be \"similar.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a5032",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A \"good\" choice of features depends on many factors:\n",
    "    - The kind of data, i.e. quantitative, ordinal, or nominal.\n",
    "    - The relationship(s) being modeled.\n",
    "    - The model type, e.g. linear models, decision tree models, neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac781d68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To introduce different feature functions, we'll look at several different example datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e155a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4f970",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is a transformation that turns a categorical feature into several binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce40fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose a column has $N$ unique values, $A_1$, $A_2$, ..., $A_N$. For each unique value $A_i$, we define the following **feature function**:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65ebda",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that 1 means \"yes\" and 0 means \"no\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c38fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is also called \"dummy encoding\", and $\\phi(x)$ may also be referred to as an \"indicator variable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc658794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding `'smoker'`\n",
    "\n",
    "For each unique value of `'smoker'` in our dataset, we must create a column for just that `'smoker'`. (Remember, `'smoker'` is `'Yes'` when the table was in the smoking section of the restaurant and `'No'` otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c21be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(tips['smoker'] == 'Yes').astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in tips['smoker'].unique():\n",
    "    tips[f'smoker == {val}'] = (tips['smoker'] == val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ccee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #4: Multiple linear regression using total bill, table size, and smoker status\n",
    "\n",
    "Now that we've converted `'smoker'` to a numerical variable, we can use it as input in a regression model. Here's the model we'll try to fit:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size} + w_3 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9911e95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Subtlety**: There's no need to use _both_ `'smoker == No'` and `'smoker == Yes'`. If we know the value of one, we already know the value of the other. We can use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three = LinearRegression()\n",
    "model_three.fit(tips[['total_bill', 'size', 'smoker == Yes']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c29f19",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "The following cell gives us our $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08d4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_three.intercept_, model_three.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685cb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, our trained linear model to predict tips given total bills, table sizes, and smoker status (yes or no) is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a31b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing Model #4\n",
    "\n",
    "Our new fit model is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$\n",
    "\n",
    "To visualize our data and linear model, we'd need 4 dimensions:\n",
    "- One for total bill\n",
    "- One for table size\n",
    "- One for `'smoker == Yes'`.\n",
    "- One for tip.\n",
    "\n",
    "Humans can't visualize in 4D, but there may be a solution. We know that `'smoker == Yes'` only has two possible values, 1 or 0, so let's look at those cases separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f67d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Case 1**: `'smoker == Yes'` is 1, meaning that the table **was** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 1 \\\\ &= 0.626 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac8dde",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Case 2**: `'smoker == Yes'` is 0, meaning that the table **was not** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 0 \\\\ &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e760d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: These are two parallel planes in 3D, with different $z$-intercepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3f2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the two planes are very close to one another ‚Äì you'll have to zoom in to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.renderers.default = 'plotly_mimetype+notebook' # If it doesn't render, try uncommenting this.\n",
    "\n",
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z_0 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 0\n",
    "Z_1 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 1\n",
    "plane_0 = go.Surface(x=XX, y=YY, z=Z_0, colorscale='Greens')\n",
    "plane_1 = go.Surface(x=XX, y=YY, z=Z_1, colorscale='Purples')\n",
    "\n",
    "fig = go.Figure(data=[plane_0, plane_1])\n",
    "\n",
    "tips_0 = tips[tips['smoker'] == 'No']\n",
    "tips_1 = tips[tips['smoker'] == 'Yes']\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_0['total_bill'], \n",
    "                           y=tips_0['size'], \n",
    "                           z=tips_0['tip'], mode='markers', marker = {'color': 'green'}))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_1['total_bill'], \n",
    "                           y=tips_1['size'], \n",
    "                           z=tips_1['tip'], mode='markers', marker = {'color': 'purple'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'),\n",
    "  title='Tip vs. Total Bill and Table Size (Green = Non-Smoking Section, Purple = Smoking Section)',\n",
    "    width=1000, height=800,\n",
    "    showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2302b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to visualize in 2D, we need to pick a single feature to place on the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45adfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], \n",
    "                         mode='markers', name='Original Data'))\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]), \n",
    "                         mode='markers', name='Predicted Tips using Total Bill, <br>Table Size, and Smoker Status'))\n",
    "\n",
    "fig.update_layout(showlegend=True, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6c67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Despite being a linear model, why **doesn't** this model **look** like a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36750de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Model #4 to earlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['three features'] = rmse(tips['tip'], \n",
    "                                   model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]))\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding `'smoker == Yes'` decreased the training RMSE of our model, but **barely**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c9803",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "What questions do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cdc3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201375c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've one hot encoded `'smoker'`, but it required a `for`-loop.\n",
    "\n",
    "- Is there an easy way to one hot encode all four categorical columns ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'` ‚Äì all at once, without using a `for`-loop?\n",
    "\n",
    "- Yes, using `sklearn.preprocessing`'s `OneHotEncoder`. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7705f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Predicting ratings ‚≠êÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d7777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting ratings ‚≠êÔ∏è\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646aaeb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to build a **classifier** that predicts `'RATING'` using the above features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5be580",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why can't we build a model right away? What must we do so that we can build a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d686e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some issues: missing values, emojis and strings instead of numbers, irrelevant columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94368ca4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uninformative features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afc37c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'UID'` was likely used to join the user information (e.g., `'AGE'` and `'STATE'`) with some `reviews` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f18a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even though `'UID'`s are stored as **numbers**, the numerical value of a user's `'UID'` won't help us predict their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf001f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we include the `'UID'` feature, our model will find whatever patterns it can between `'UID'`s and `'RATING'`s in the training (observed data).\n",
    "    - This will lead to a lower training RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ad1e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, since there is truly no relationship between `'UID'` and `'RATING'`, this will lead to **worse** model performance on unseen data (bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c96d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. When the features **do not contain information** associated with the prediction task. \n",
    "2. When the feature is **not available at prediction time.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb7f8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The goal of building a model to predict `'RATING'`s is so that we can **predict `'RATING'`s for users who haven't actually made a `'RATING'` yet**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac16bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, our model should only depend on features that we would know before the user makes their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b286ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, if a user only enters a `'REVIEW'` after entering a `'RATING'`, we shouldn't use their `'REVIEW'` to predict their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574cfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding ordinal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'RATING'` column, an ordinal variable, as a quantitative variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c558ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Transformation**: Replace \"number of &#10025;\" with \"number\".\n",
    "    - This is an **ordinal encoding**, a transformation that maps ordinal values to the positive integers in a way that preserves order.\n",
    "    - Example: (freshman, sophomore, junior, senior) -> (0, 1, 2, 3).\n",
    "    - **Important**: This transformation preserves \"distances\" between ratings.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_enc = {\n",
    "    '‚ú©': 1,\n",
    "    '‚ú©‚ú©': 2,\n",
    "    '‚ú©‚ú©‚ú©': 3,\n",
    "    '‚ú©‚ú©‚ú©‚ú©': 4,\n",
    "    '‚ú©‚ú©‚ú©‚ú©‚ú©': 5,\n",
    "}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame().assign(RATING=['‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©‚ú©'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebe95e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding nominal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'STATE'` column, a nominal variable, as a quantitative variable? In other words, how do we turn `'STATE'`s into meaningful numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d752d5c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Why can't we use an ordinal encoding, e.g. NY -> 0, WA -> 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966caa51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: There is no inherent ordering to states, e.g. WA is not inherently \"more\" of anything than NY."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211cf3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We've already seen the correct strategy**: one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6cb7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Horsepower üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31c6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following dataset, built into the `seaborn` plotting library, contains various information about (older) cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74629562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg').dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b32614",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We really do mean old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['model_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30a172",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's investigate the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3bf75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between `'horsepower'` and `'mpg'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5268d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='horsepower', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887d19e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It appears that there is a negative association between `'horsepower'` and `'mpg'`, though it's not quite linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c3860",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try and fit a simple linear model that uses `'horsepower'` to predict `'mpg'` and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08a100",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `'horsepower'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model = LinearRegression()\n",
    "car_model.fit(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_points = pd.DataFrame({'horsepower': [25, 225]})\n",
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=hp_points['horsepower'],\n",
    "    y=car_model.predict(hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using Horsepower'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our regression line doesn't capture the curvature in the relationship between `'horsepower'` and `'mpg'`.\n",
    "\n",
    "Let's look at the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mpg.assign(\n",
    "    Predictions=car_model.predict(mpg[['horsepower']]),\n",
    "    Residuals=mpg['mpg'] - car_model.predict(mpg[['horsepower']]),\n",
    ")\n",
    "fig = px.scatter(res, x='Predictions', y='Residuals')\n",
    "fig.add_hline(0, line_width=3, opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model.score(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3ec7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linearization\n",
    "\n",
    "The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which transformations to apply to data in order to **linearize** it.\n",
    "\n",
    "<center><img src=\"imgs/bulge.png\" width=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164a12",
   "metadata": {},
   "source": [
    "The bottom-left quadrant appears to match the shape of the scatter plot between `'horsepower'` and `'mpg'` the best ‚Äì let's try taking the `log` of `'horsepower'` ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['log hp'] = np.log(mpg['horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b77c02",
   "metadata": {},
   "source": [
    "What does our data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='log hp', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686dfcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `log('horsepower')`\n",
    "\n",
    "Let's fit another linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12526744",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log = LinearRegression()\n",
    "car_model_log.fit(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e490f0",
   "metadata": {},
   "source": [
    "What do our predictions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e44922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "log_hp_points = pd.DataFrame({'log hp': [3.7, 5.5]})\n",
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=log_hp_points['log hp'],\n",
    "    y=car_model_log.predict(log_hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using log(Horsepower)'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fe456",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fit looks a bit better! How about the $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.score(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1fa5",
   "metadata": {},
   "source": [
    "Also a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724aa37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do our predictions look like on the original, non-transformed scatter plot? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=mpg['horsepower'], \n",
    "        y=car_model_log.intercept_ + car_model_log.coef_[0] * np.log(mpg['horsepower']),  \n",
    "        mode='markers', name='Predicted MPG using log(Horsepower)'\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93afa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our predictions that used $\\log(\\text{Horsepower})$ as an input don't fall on a straight line. We shouldn't expect them to; the red dots come from:\n",
    "\n",
    "$$\\text{Predicted MPG} = 108.698 - 18.582 \\cdot \\log(\\text{Horsepower})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.intercept_, car_model_log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7081a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantitative scaling\n",
    "\n",
    "Until now, feature transformations we've discussed so far have involved converting **categorical** variables into **quantitative** variables. However, our log transformation was an example of transforming a **quantitative** variable into a new **quantitative** variable; this practice is called quantitative scaling.\n",
    "\n",
    "- **Standardization**: $x_i \\rightarrow \\frac{x_i - \\bar{x}}{\\sigma_x}$.\n",
    "- **Linearization via a non-linear transformation**: e.g. $\\text{log}$ and $\\text{sqrt}$. See Lab 8 for more.\n",
    "- **Discretization**: Convert data into percentiles (or more generally, quantiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adde80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "What questions do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a95ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14ddab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26e1d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Create, or engineer, features to best reflect the \"meaning\" behind data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e645a03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a model that is appropriate to capture the relationships between features ($X$) and the target/response ($y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92866e92",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Choose a loss function, e.g. squared loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05939d0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Fit the model: that is, minimize empirical risk to find optimal model parameters $w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b9e78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Evaluate the model, e.g. using RMSE or $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbedad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**We can perform all of the above directly in `sklearn`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91d26c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7f04d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_model`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc00479",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **feature engineering** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<center><img src=\"imgs/feature_part.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795bf90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module, as we've already seen. `linear_model.LinearRegression` is an example of an **estimator** class.\n",
    "\n",
    "<center><img src=\"imgs/model_part.png\" width=\"36%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813b18b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41403a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b832c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297cd26",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The input to a transformer should be a multi-dimensional `numpy` array.\n",
    "    - Inputs can be DataFrames, but `sklearn` only looks at the values (i.e. it calls `to_numpy()` on input DataFrames)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc20389",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The output of a transformer is a `numpy` array (never a DataFrame or Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f3995",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f64cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting tips üßë‚Äçüç≥\n",
    "\n",
    "We'll continue working with our trusty `tips` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159c00f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `Binarizer`\n",
    "\n",
    "The `Binarizer` transformer allows us to map a quantitative sequence to a sequence of 1s and 0s, depending on whether values are above or below a threshold.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | set x=1 if x > thresh, else 0|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec5acd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we need to import the relevant class from `sklearn.preprocessing`. (Tip: import just the relevant classes you need from `sklearn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95076bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80843c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try binarizing `'total_bill'`. We'll say a \"large\" bill is one that is **strictly** greater than \\$20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f125d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips['total_bill'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8186086",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we initialize a `Binarizer` object with the threshold we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Binarizer(threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611bda9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we call `bi`'s `transform` method and pass it the data we'd like to transform. Note that its input and output are both 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_bills = bi.transform(tips[['total_bill']]) # Must give transform a 2D array/DataFrame.\n",
    "transformed_bills[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc577d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b7e11",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `StandardScaler` **standardizes** data using the mean and standard deviation of the data.\n",
    "\n",
    "$$z(x_i) = \\frac{x_i - \\text{mean of } x}{\\text{SD of } x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf57ce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unlike `Binarizer`, `StandardScaler` **requires some knowledge (mean and SD) of the dataset before transforming**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2ac75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we need to **`fit`** an `StandardScaler` transformer before we can use the `transform` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347e31a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Typical usage: fit transformer on a sample, use that fit transformer to transform future data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bbeaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`\n",
    "\n",
    "It only makes sense to standardize the already-quantitative features of `tips`, so let's select just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_quant = tips[['total_bill', 'size']]\n",
    "tips_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d684be1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's initialize a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03790dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the following **does not work!** The error message is very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b96342",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6d884",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, we need to first call the `fit` method on `stdscaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is like saying \"determine the mean and SD of each column in tips_quant\".\n",
    "stdscaler.fit(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f4d3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, `transform` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column is 'total_bill', second column is 'size'.\n",
    "tips_quant_z = stdscaler.transform(tips_quant)\n",
    "tips_quant_z[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fc339",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also access the mean and variance `stdscaler` computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f412d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89daaa5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that we can call `transform` on DataFrames other than `tips_quant`. We will do this often ‚Äì fit a transformer on one dataset (training data) and use it to transform other datasets (test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935239f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí° Pro-Tip: Using `.fit_transform`\n",
    "\n",
    "The `.fit_transform` method will fit the transformer and then transform the data in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf51fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.fit_transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6481695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `StandardScaler` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-score the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(X)` | Compute the mean and SD of `X`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(X_new)` | z-score `X_new` with mean and SD of `X`|\n",
    "|Fit and transform| `stdscaler.fit_transform(X)` | Compute the mean and SD of `X`, then z-score `X`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d017d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `OneHotEncoder`\n",
    "\n",
    "Let's keep just the categorical columns in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f3536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af220ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Like `StdScaler`, we will need to `fit` our `OneHotEncoder` transformer before it can transform anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f412324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373090e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we try and transform, we get a result we might not expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee74801",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ae7a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the resulting matrix is **sparse** ‚Äì most of its elements are 0 ‚Äì `sklearn` uses a more efficient representation than a regular `numpy` array. We can convert to a regular (dense) array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aabf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(tips_cat).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6195a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the column names from `tips_cat` are no longer stored anywhere (remember, `fit` converts the input to a `numpy` array before proceeding).\n",
    "\n",
    "We can use the `get_feature_names_out` method on `ohe` to access the names of the one-hot-encoded columns, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out() # x0, x1, x2, and x3 correspond to column names in tips_cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ohe.transform(tips_cat).toarray(), \n",
    "             columns=ohe.get_feature_names_out()) # If we need a DataFrame back, for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833fac9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f71de5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "So far, we've used transformers for feature engineering and models for prediction. We can combine these steps into a single `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1ef16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Pipeline`s in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534d8e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From [`sklearn`'s documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):\n",
    "\n",
    "> Pipeline allows you to sequentially apply a list of transformers to preprocess the data and, **if desired**, conclude the sequence with a final predictor for predictive modeling.<br><br>Intermediate steps of the pipeline must be \"transforms\", that is, they must implement `fit` and `transform` methods. The final estimator only needs to implement `fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1553e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- General template: `pl = Pipeline([trans_1, trans_2, ..., model])`\n",
    "    - Note that the `model` is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a409a1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once a `Pipeline` is instantiated, you can fit **all** steps (transformers and model) using `pl.fit(X, y)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170591a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To make predictions using **raw, untransformed data**, use `pl.predict(X)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508398a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The actual list we provide `Pipeline` with must be a list of **tuples**, where\n",
    "    - The first element is a \"name\" (that we choose) for the step.\n",
    "    - The second element is a transformer or estimator instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86669e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our first `Pipeline`\n",
    "\n",
    "Let's build a `Pipeline` that:\n",
    "- One hot encodes the categorical features in `tips`.\n",
    "- Fits a regression model on the one hot encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03859c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49f763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('one-hot', OneHotEncoder()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ef92c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that `pl` is instantiated, we `fit` it the same way we would fit the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03991a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_cat, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b902c9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, to make predictions using **raw data**, all we need to do is use `pl.predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(tips_cat.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8518b9",
   "metadata": {},
   "source": [
    "`pl` performs **both** feature transformation and prediction with just a single call to `predict`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea45098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access individual \"steps\" of a `Pipeline` through the `named_steps` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c6298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].transform(tips_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f17401",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['lin-reg'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7b1ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pl` also has a `score` method, the same way a fit `LinearRegression` instance does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this so low?\n",
    "pl.score(tips_cat, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fc2ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More sophisticated `Pipeline`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aeac87",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the previous example, we one hot encoded every input column. **What if we want to perform different transformations on different columns?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877bd69",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Use a `ColumnTransformer`.\n",
    "    - Instantiate a `ColumnTransformer` using a list of tuples, where:\n",
    "        - The first element is a \"name\" we choose for the transformer.\n",
    "        - The second element is a transformer instance (e.g. `OneHotEncoder()`).\n",
    "        - The third element is a **list of relevant column names**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477c359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Planning our first `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd28cf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ecc2b",
   "metadata": {},
   "source": [
    "Let's perform different transformations on the quantitative and categorical features of `tips` (note that we are not transforming `'tip'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_features = tips.drop('tip', axis=1)\n",
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b564152",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We will leave the `'total_bill'` column untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab25c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To the `'size'` column, we will apply the `Binarizer` transformer with a threshold of 2 (big tables vs. small tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39414c70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To the categorical columns, we will apply the `OneHotEncoder` transformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05895b8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In essence, we will create a transformer that reproduces the following DataFrame:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>size</th>\n",
    "      <th>x0_Female</th>\n",
    "      <th>x0_Male</th>\n",
    "      <th>x1_No</th>\n",
    "      <th>x1_Yes</th>\n",
    "      <th>x2_Fri</th>\n",
    "      <th>x2_Sat</th>\n",
    "      <th>x2_Sun</th>\n",
    "      <th>x2_Thur</th>\n",
    "      <th>x3_Dinner</th>\n",
    "      <th>x3_Lunch</th>\n",
    "      <th>total_bill</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>16.99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>10.34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>21.01</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>23.68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>24.59</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a `Pipeline` using a `ColumnTransformer`\n",
    "\n",
    "Let's start by creating our `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5854",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('size', Binarizer(threshold=2), ['size']),\n",
    "        ('categorical_cols', OneHotEncoder(), ['sex', 'smoker', 'day', 'time'])\n",
    "    ],\n",
    "    remainder='passthrough' # Specify what to do with all other columns ('total_bill' here) ‚Äì drop or passthrough.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f5569",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, let's create a `Pipeline` using `preproc` as a transformer, and `fit` it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('preprocessor', preproc), \n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_features, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5db465",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prediction is as easy as calling `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we fit the Pipeline using tips_features, not tips_features.head()!\n",
    "pl.predict(tips_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b1a71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `FunctionTransformer`\n",
    "\n",
    "A transformer you'll often use as part of a `ColumnTransformer` is the `FunctionTransformer`, which enables you to use your own functions on entire columns. Think of it as the `sklearn` equivalent of `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FunctionTransformer(np.sqrt)\n",
    "f.transform([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762df65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f679d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- To transform a categorical nominal variable into a quantitative variable, use one hot encoding.\n",
    "- To transform a categorical ordinal variable into a quantitative variable, use an ordinal encoding.\n",
    "- Quantitative feature transformations allow us to use linear models to model non-linear data.\n",
    "- `Pipeline`s are powerful because they allow you to perform feature engineering and training/prediction all through a single object.\n",
    "- As we'll see next time, they also allow us to easily compare models against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24f95a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- More examples of, and ways to create, `Pipeline`s.\n",
    "- Multicollinearity.\n",
    "- Generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
